{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG using DSPy & OpenAI\n",
    "\n",
    "In this notebook, we'll build a full RAG framework using the trained and indexed retrieval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "import json\n",
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dspy.datasets import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dsp.utils import deduplicate\n",
    "from rich import print\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring dspy\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "turbo = turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_api_key)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset we'll use to train our RAG system\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the trained retrieval model\n",
    "def query_index(query: str, topk: int):\n",
    "\n",
    "    # provide the path to your index\n",
    "    index_path = \".ragatouille/colbert/indexes/EPL\"\n",
    "    try:\n",
    "        RAG = RAGPretrainedModel.from_index(index_path=index_path)\n",
    "        return RAG.search(query=query, k=topk)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Index not found: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature\n",
    "class GenerateAnswer(dspy.Signature): \n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 100 words\")\n",
    "    \n",
    "# Module / Pipeline\n",
    "class RAG(dspy.Module): \n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        #self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.topk = num_passages\n",
    "    \n",
    "    def forward(self, question):\n",
    "        #context = self.retrieve(question).passages\n",
    "        context_dict = query_index(query=question, topk=self.topk)\n",
    "        context = [x['content'] for x in context_dict]\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "# Optimizer / Optimising Pipeline\n",
    "def validate_context_and_answer(example, pred, trace=None): \n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:25] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:13:28] #> Loading codec...\n",
      "[May 13, 02:13:28] #> Loading IVF...\n",
      "[May 13, 02:13:28] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[May 13, 02:13:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1049.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:28] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:28] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . At My Window was released by which American singer-songwriter?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2012, 2026, 3332, 2001, 2207, 2011, 2029, 2137, 3220, 1011,\n",
      "        6009, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "  5%|▌         | 1/20 [00:10<03:14, 10.23s/it]/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:13:37] #> Loading codec...\n",
      "[May 13, 02:13:37] #> Loading IVF...\n",
      "[May 13, 02:13:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3483.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . which  American actor was Candace Kita  guest starred with , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2137,  3364,  2001, 22905,  8934,  2050,  4113,\n",
      "         5652,  2007,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      " 10%|█         | 2/20 [00:18<02:47,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:13:46] #> Loading codec...\n",
      "[May 13, 02:13:46] #> Loading IVF...\n",
      "[May 13, 02:13:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 915.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which of these publications was most recently published, Who Put the Bomp or Self?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2029, 1997, 2122, 5523, 2001, 2087, 3728, 2405, 1010, 2040,\n",
      "        2404, 1996, 8945, 8737, 2030, 2969, 1029,  102,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [00:28<02:37,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:13:55] #> Loading codec...\n",
      "[May 13, 02:13:55] #> Loading IVF...\n",
      "[May 13, 02:13:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2981.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:13:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1996, 6652, 2015, 1011, 2037, 2466, 1999, 4620, 2003, 1037,\n",
      "        4516, 2186, 2517, 2011, 2019, 3166, 2141, 1999, 2054, 2095, 1029,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [00:37<02:32,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:05] #> Loading codec...\n",
      "[May 13, 02:14:05] #> Loading IVF...\n",
      "[May 13, 02:14:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1006.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2932,  2038,  2405,  4790,  2011,  3660,  8233,\n",
      "         1010, 22297,  6448,  2239,  2079,  2335,  2030,  4943,  2396,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [00:47<02:20,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:14] #> Loading codec...\n",
      "[May 13, 02:14:14] #> Loading IVF...\n",
      "[May 13, 02:14:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 974.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . In what year was the club founded that played Manchester City in the 1972 FA Charity Shield, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1999, 2054, 2095, 2001, 1996, 2252, 2631, 2008, 2209, 5087,\n",
      "        2103, 1999, 1996, 3285, 6904, 5952, 6099,  102,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [00:57<02:18,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:25] #> Loading codec...\n",
      "[May 13, 02:14:25] #> Loading IVF...\n",
      "[May 13, 02:14:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3663.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which is taller, the Empire State Building or the Bank of America Tower?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2003, 12283,  1010,  1996,  3400,  2110,  2311,\n",
      "         2030,  1996,  2924,  1997,  2637,  3578,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [01:11<02:25, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:40] #> Loading codec...\n",
      "[May 13, 02:14:40] #> Loading IVF...\n",
      "[May 13, 02:14:40] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:40] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2137,  3883,  2040,  2081,  2037,  2143,  2834,\n",
      "         1999,  1996,  2786,  9458,  3689,  1000,  4268,  1000,  2001,  1996,\n",
      "         2522,  1011,  3910,  1997, 29536,  3406,  7402,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [01:19<02:02, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:47] #> Loading codec...\n",
      "[May 13, 02:14:47] #> Loading IVF...\n",
      "[May 13, 02:14:47] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 969.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:47] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Tombstone stared an actor born May 17, 1955 known as who?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 26671,  3592,  2019,  3364,  2141,  2089,  2459,  1010,\n",
      "         3982,  2124,  2004,  2040,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [01:28<01:47,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:14:55] #> Loading codec...\n",
      "[May 13, 02:14:55] #> Loading IVF...\n",
      "[May 13, 02:14:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1650.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:14:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([48]), tensor([ 101,    1, 2054, 2003, 1996, 3642, 2171, 2005, 1996, 2446, 5805, 2008,\n",
      "        2318, 2023, 2117, 2088, 2162, 8147, 2006, 1996, 2789, 2392, 1006, 1037,\n",
      "        2261, 3634, 7338, 2013, 4924, 1007, 2090, 3354, 1998, 2446, 2749, 1010,\n",
      "        2029, 2443, 9402, 4859, 3939, 2407, 1029,  102,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([48]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [01:37<01:34,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:04] #> Loading codec...\n",
      "[May 13, 02:15:04] #> Loading IVF...\n",
      "[May 13, 02:15:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 824.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([36]), tensor([  101,     1,  2040,  6051,  1999,  1996,  2915,  2143,  1996,  5370,\n",
      "         1998,  2003,  2036,  1996,  6587,  3883,  2412,  2000,  2377,  6728,\n",
      "        16001,  2401,  1999,  1037,  2548,  8101,  2194,  2537,  1997,  1000,\n",
      "         8429,  1012,  1000,  1029,   102,   103])\n",
      "#> Output Mask: torch.Size([36]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [01:44<01:17,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:11] #> Loading codec...\n",
      "[May 13, 02:15:11] #> Loading IVF...\n",
      "[May 13, 02:15:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2336.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2194,  5500,  2023,  3355,  2137,  6579,  2143,\n",
      "         2550,  2011, 10598,  6373,  5453,  2005,  2029, 11011,  3428,  2626,\n",
      "         2774,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [01:52<01:07,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:19] #> Loading codec...\n",
      "[May 13, 02:15:19] #> Loading IVF...\n",
      "[May 13, 02:15:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 917.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 11415, 13675, 20483, 29278, 18319,  1998,  2928, 10382,\n",
      "         5172,  2024,  2119,  2190,  2124,  2005,  2108,  2034,  1999,  2037,\n",
      "         2492,  2000,  2175,  2073,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [02:00<00:59,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:27] #> Loading codec...\n",
      "[May 13, 02:15:27] #> Loading IVF...\n",
      "[May 13, 02:15:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2345.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2383,  1996,  5257,  1997,  6581,  3329,  3177,  1998,\n",
      "         7151,  3177,  3271,  4388,  4482,  1010,  3443,  2054,  2785,  1997,\n",
      "         2041,  3790,  2005,  1996,  3050,  3349, 13391,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [02:08<00:50,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:36] #> Loading codec...\n",
      "[May 13, 02:15:36] #> Loading IVF...\n",
      "[May 13, 02:15:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3216.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([35]), tensor([  101,     1,  2029,  9889,  4533, 20887,  2040,  2180,  1017,  5486,\n",
      "        16461, 20887,  1997,  1996,  2095,  2982,  1999,  2268,  1010,  2230,\n",
      "         1010,  1998,  2249,  2097,  2022,  1999,  1996, 16461,  2088, 22240,\n",
      "         1029,   102,   103,   103,   103])\n",
      "#> Output Mask: torch.Size([35]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [02:18<00:44,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:46] #> Loading codec...\n",
      "[May 13, 02:15:46] #> Loading IVF...\n",
      "[May 13, 02:15:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1184.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1996,  5502,  2008,  4473,  1037,  2451,  2000,  3747,\n",
      "         2037,  3169,  2030,  2224,  1998,  2000,  5959,  1996,  6666, 17707,\n",
      "        17311,  2631,  1999,  2054,  2095,  1029,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [02:30<00:39,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:15:58] #> Loading codec...\n",
      "[May 13, 02:15:58] #> Loading IVF...\n",
      "[May 13, 02:15:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3172.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:15:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Everything Has Changed\" is a song from an album released under which record label ?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2673, 2038, 2904, 1000, 2003, 1037, 2299, 2013, 2019,\n",
      "        2201, 2207, 2104, 2029, 2501, 3830, 1029,  102,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [02:36<00:26,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:16:04] #> Loading codec...\n",
      "[May 13, 02:16:04] #> Loading IVF...\n",
      "[May 13, 02:16:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 541.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:16:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2003,  3080,  1010, 24020, 19522, 29356,  2232,\n",
      "        24020,  4492,  2030,  9617,  3406,  2135,  1042,  8462, 16107,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [02:44<00:16,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:16:12] #> Loading codec...\n",
      "[May 13, 02:16:12] #> Loading IVF...\n",
      "[May 13, 02:16:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 995.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:16:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . On the coast of what ocean is the birthplace of Diogal Sakho?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2006,  1996,  3023,  1997,  2054,  4153,  2003,  1996,\n",
      "        14508,  1997,  4487, 18170,  2140,  7842, 10023,  2080,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [02:52<00:08,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:16:20] #> Loading codec...\n",
      "[May 13, 02:16:20] #> Loading IVF...\n",
      "[May 13, 02:16:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 900.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:16:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2023,  2137,  5990,  2190,  2124,  2005,  2014,  2147,\n",
      "         2007,  1996,  3707, 10494,  2015,  2003,  2019, 13032,  1997,  1037,\n",
      "         4543,  2040,  2001,  2124,  2004,  2054,  1029,   102,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [03:02<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer) \n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:16:57] #> Loading codec...\n",
      "[May 13, 02:16:57] #> Loading IVF...\n",
      "[May 13, 02:16:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1839.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:16:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which club has the record for the longest unbeaten run in the premier league?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2252,  2038,  1996,  2501,  2005,  1996,  6493,\n",
      "        20458,  2448,  1999,  1996,  4239,  2223,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"Which club has the record for the longest unbeaten run in the premier league?\"\n",
    "pred = compiled_rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Which club has the record for the longest unbeaten run in the premier league?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Which club has the record for the longest unbeaten run in the premier league?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicted Answer: Arsenal\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Predicted Answer: Arsenal\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Contexts <span style=\"font-weight: bold\">(</span>truncated<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Arsenal hold the record for the longest run of unbeaten League matches (49 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between May 2003 and October 2004). This included all 38 matches of their title-winning 2003–04 season, when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arsenal became o...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">period in the 1930s. He helped introduce the WM formation, floodlights, and shirt numbers; he also added the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">wh...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Chelsea hold the English record for the fewest goals conceded during a league season (15), the highest </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of clean sheets overall in a Premier League season (25) (both set during the 2004–05 seaso...'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Contexts \u001b[1m(\u001b[0mtruncated\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Arsenal hold the record for the longest run of unbeaten League matches \u001b[0m\u001b[32m(\u001b[0m\u001b[32m49 \u001b[0m\n",
       "\u001b[32mbetween May 2003 and October 2004\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This included all 38 matches of their title-winning 2003–04 season, when \u001b[0m\n",
       "\u001b[32mArsenal became o...'\u001b[0m, \u001b[32m'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden \u001b[0m\n",
       "\u001b[32mperiod in the 1930s. He helped introduce the WM formation, floodlights, and shirt numbers; he also added the \u001b[0m\n",
       "\u001b[32mwh...'\u001b[0m, \u001b[32m'Chelsea hold the English record for the fewest goals conceded during a league season \u001b[0m\u001b[32m(\u001b[0m\u001b[32m15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the highest \u001b[0m\n",
       "\u001b[32mnumber of clean sheets overall in a Premier League season \u001b[0m\u001b[32m(\u001b[0m\u001b[32m25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mboth set during the 2004–05 seaso...'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Question: {query}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncompile Baleen without Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:18:50] #> Loading codec...\n",
      "[May 13, 02:18:50] #> Loading IVF...\n",
      "[May 13, 02:18:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 966.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:18:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are both Cangzhou and Qionghai in the Hebei province of China?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024,  2119,  2064,  2290,  9791,  1998, 18816,  5063,\n",
      "        10932,  1999,  1996,  2002, 19205,  2874,  1997,  2859,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0):   2%|▏         | 1/50 [00:17<14:11, 17.38s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:07] #> Loading codec...\n",
      "[May 13, 02:19:07] #> Loading IVF...\n",
      "[May 13, 02:19:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1020.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040, 17976,  1996,  4433,  1999,  2029,  7871,  1011,\n",
      "         7213, 13109, 11236,  2100,  2001,  7462,  2000,  1996,  7136,  3585,\n",
      "         7307,  2005,  1996,  2418,  1011,  2324,  2161,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   4%|▍         | 2/50 [00:25<09:27, 11.82s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:15] #> Loading codec...\n",
      "[May 13, 02:19:15] #> Loading IVF...\n",
      "[May 13, 02:19:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3061.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay Lightning of the National Hockey League (NHL)?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([43]), tensor([ 101,    1, 1996, 4777, 3133, 1037, 2047, 3690, 1010, 2206, 1996, 5075,\n",
      "        1997, 2029, 3010, 3394, 2658, 3256, 3873, 2447, 1998, 2783, 2236, 3208,\n",
      "        1997, 1996, 9925, 3016, 7407, 1997, 1996, 2120, 3873, 2223, 1006, 7097,\n",
      "        1007, 1029,  102,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([43]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):   6%|▌         | 3/50 [00:33<07:58, 10.19s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:23] #> Loading codec...\n",
      "[May 13, 02:19:23] #> Loading IVF...\n",
      "[May 13, 02:19:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 970.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What river is near the Crichton Collegiate Church?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2314,  2003,  2379,  1996, 13675,  7033,  2669,\n",
      "         9234,  2277,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 4  (0.0):   8%|▊         | 4/50 [00:40<06:43,  8.77s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:30] #> Loading codec...\n",
      "[May 13, 02:19:30] #> Loading IVF...\n",
      "[May 13, 02:19:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1017.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  1996,  6049,  2301,  1037,  1012,  1040,  1012,\n",
      "        19413,  2140,  7898, 24415,  2018,  1037,  2365,  2170,  1097, 10760,\n",
      "         2140, 16689,  2094,  2011,  2029,  2394,  2332,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 5  (0.0):  10%|█         | 5/50 [00:47<06:05,  8.13s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:37] #> Loading codec...\n",
      "[May 13, 02:19:37] #> Loading IVF...\n",
      "[May 13, 02:19:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3942.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . The Newark Airport Exchange is at the northern edge of an airport that is operated by whom?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1996, 12948,  3199,  3863,  2003,  2012,  1996,  2642,\n",
      "         3341,  1997,  2019,  3199,  2008,  2003,  3498,  2011,  3183,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 6  (0.0):  12%|█▏        | 6/50 [00:56<06:17,  8.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:19:46] #> Loading codec...\n",
      "[May 13, 02:19:46] #> Loading IVF...\n",
      "[May 13, 02:19:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1259.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:19:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Where did an event take place resulting in a win during a domestic double due to the action of a Peruvian footballer known for his goal scoring ability?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([37]), tensor([  101,     1,  2073,  2106,  2019,  2724,  2202,  2173,  4525,  1999,\n",
      "         1037,  2663,  2076,  1037,  4968,  3313,  2349,  2000,  1996,  2895,\n",
      "         1997,  1037, 15432,  4362,  2124,  2005,  2010,  3125,  4577,  3754,\n",
      "         1029,   102,   103,   103,   103,   103,   103])\n",
      "#> Output Mask: torch.Size([37]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 7  (0.0):  14%|█▍        | 7/50 [01:12<07:44, 10.81s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:02] #> Loading codec...\n",
      "[May 13, 02:20:02] #> Loading IVF...\n",
      "[May 13, 02:20:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1506.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are both Chico Municipal Airport and William R. Fairchild International Airport in California?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024,  2119, 22136,  4546,  3199,  1998,  2520,  1054,\n",
      "         1012, 24258,  2248,  3199,  1999,  2662,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 8  (0.0):  16%|█▌        | 8/50 [01:20<07:08, 10.19s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:11] #> Loading codec...\n",
      "[May 13, 02:20:11] #> Loading IVF...\n",
      "[May 13, 02:20:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1365.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . In which Maine county is Fort Pownall located?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  7081,  2221,  2003,  3481, 23776, 22270,\n",
      "         2284,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 9  (0.0):  18%|█▊        | 9/50 [01:29<06:39,  9.74s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:20] #> Loading codec...\n",
      "[May 13, 02:20:20] #> Loading IVF...\n",
      "[May 13, 02:20:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3008.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which 90s rock band has more recently reformed, Gene or The Afghan Whigs?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029, 17233,  2600,  2316,  2038,  2062,  3728,  9114,\n",
      "         1010,  4962,  2030,  1996, 12632, 21632,  2015,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 10  (0.0):  20%|██        | 10/50 [01:39<06:26,  9.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:29] #> Loading codec...\n",
      "[May 13, 02:20:29] #> Loading IVF...\n",
      "[May 13, 02:20:29] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3371.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:29] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What year did the mountain known in Italian as \"Monte Vesuvio\", erupt?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2095,  2106,  1996,  3137,  2124,  1999,  3059,\n",
      "         2004,  1000, 10125,  2310,  6342, 25500,  1000,  1010,  9413, 29441,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 11  (0.0):  22%|██▏       | 11/50 [01:47<05:59,  9.22s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:37] #> Loading codec...\n",
      "[May 13, 02:20:37] #> Loading IVF...\n",
      "[May 13, 02:20:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 922.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Is the 72nd field brigade part of the oldest or newest established field army?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2003,  1996,  5824,  4859,  2492,  4250,  2112,  1997,\n",
      "         1996,  4587,  2030, 14751,  2511,  2492,  2390,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 12  (0.0):  24%|██▍       | 12/50 [02:00<06:39, 10.51s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:50] #> Loading codec...\n",
      "[May 13, 02:20:50] #> Loading IVF...\n",
      "[May 13, 02:20:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1084.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Was Stanislaw Kiszka paid for his services by the Royal Treasury?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2001,  9761,  2483, 14919, 11382, 17112,  2912,  3825,\n",
      "         2005,  2010,  2578,  2011,  1996,  2548,  9837,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 13  (0.0):  26%|██▌       | 13/50 [02:08<06:00,  9.73s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:20:58] #> Loading codec...\n",
      "[May 13, 02:20:58] #> Loading IVF...\n",
      "[May 13, 02:20:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 920.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:20:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which film director is younger, Del Lord or Wang Xiaoshuai?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2143,  2472,  2003,  3920,  1010,  3972,  2935,\n",
      "         2030,  7418, 19523, 14235,  4886,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 14  (0.0):  28%|██▊       | 14/50 [02:17<05:45,  9.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:08] #> Loading codec...\n",
      "[May 13, 02:21:08] #> Loading IVF...\n",
      "[May 13, 02:21:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1304.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Lord North Street has a resident in which former Conservative MP who received an 18-month prison sentence for perjury in 1999?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2935, 2167, 2395, 2038, 1037, 6319, 1999, 2029, 2280, 4603,\n",
      "        6131, 2040, 2363, 2019, 2324, 1011, 3204, 3827, 6251, 2005, 2566, 9103,\n",
      "        2854, 1999, 2639, 1029,  102,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 15  (0.0):  30%|███       | 15/50 [02:24<05:08,  8.80s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:14] #> Loading codec...\n",
      "[May 13, 02:21:14] #> Loading IVF...\n",
      "[May 13, 02:21:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 808.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the name of this region of Italy, referring to the medieval March of Ancona and nearby marches of Camerino and Fermo, where the comune Pollenza is located?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([39]), tensor([  101,     1,  2054,  2003,  1996,  2171,  1997,  2023,  2555,  1997,\n",
      "         3304,  1010,  7727,  2000,  1996,  5781,  2233,  1997,  2019, 24366,\n",
      "         1998,  3518, 20691,  1997,  2234, 17815,  1998, 10768, 10867,  2080,\n",
      "         1010,  2073,  1996, 21130, 22482,  4143,  2003,  2284,   102])\n",
      "#> Output Mask: torch.Size([39]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 16  (0.0):  32%|███▏      | 16/50 [02:32<04:48,  8.48s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:23] #> Loading codec...\n",
      "[May 13, 02:21:23] #> Loading IVF...\n",
      "[May 13, 02:21:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 696.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . William Hughes Miller was born in a city with how many inhabitants ?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2520, 8099, 4679, 2001, 2141, 1999, 1037, 2103, 2007, 2129,\n",
      "        2116, 4864, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 17  (0.0):  34%|███▍      | 17/50 [02:40<04:32,  8.26s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:30] #> Loading codec...\n",
      "[May 13, 02:21:30] #> Loading IVF...\n",
      "[May 13, 02:21:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 996.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What do students do at the school of New York University where Meleko Mokgosi is an artist and assistant professor?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2079,  2493,  2079,  2012,  1996,  2082,  1997,\n",
      "         2047,  2259,  2118,  2073, 11463,  5937,  2080,  9587,  2243, 12333,\n",
      "         2072,  2003,  2019,  3063,  1998,  3353,  2934,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 18  (0.0):  36%|███▌      | 18/50 [02:49<04:31,  8.47s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:39] #> Loading codec...\n",
      "[May 13, 02:21:39] #> Loading IVF...\n",
      "[May 13, 02:21:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3279.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996, 10662,  1997,  1996, 10026,  1998,\n",
      "         2717, 21159,  3686,  3126,  2956,  1999,  4825,  1024,  5263,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 19  (0.0):  38%|███▊      | 19/50 [02:58<04:25,  8.57s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:21:48] #> Loading codec...\n",
      "[May 13, 02:21:48] #> Loading IVF...\n",
      "[May 13, 02:21:48] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1303.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:21:48] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What American actor plays an East side drug lord who prefers peaceful solutions to business disputes when possible?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2137,  3364,  3248,  2019,  2264,  2217,  4319,\n",
      "         2935,  2040, 19233,  9379,  7300,  2000,  2449, 11936,  2043,  2825,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 20  (0.0):  40%|████      | 20/50 [03:09<04:40,  9.36s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:00] #> Loading codec...\n",
      "[May 13, 02:22:00] #> Loading IVF...\n",
      "[May 13, 02:22:00] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2631.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What city is 11 miles north of the birthplace of actor Toby Sawyer?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2103,  2003,  2340,  2661,  2167,  1997,  1996,\n",
      "        14508,  1997,  3364, 11291, 13975,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 21  (0.0):  42%|████▏     | 21/50 [03:19<04:34,  9.46s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:09] #> Loading codec...\n",
      "[May 13, 02:22:09] #> Loading IVF...\n",
      "[May 13, 02:22:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1940.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who was born first, Tony Kaye or Deepa Mehta?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2141,  2034,  1010,  4116, 23686,  2030,\n",
      "         2784,  2050,  2033, 22893,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 22  (0.0):  44%|████▍     | 22/50 [03:28<04:26,  9.53s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:18] #> Loading codec...\n",
      "[May 13, 02:22:18] #> Loading IVF...\n",
      "[May 13, 02:22:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1691.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the English translation of the name of the store that Macy's replaced in Boise Town Square?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2394,  5449,  1997,  1996,  2171,\n",
      "         1997,  1996,  3573,  2008, 20914,  1005,  1055,  2999,  1999, 23193,\n",
      "         2237,  2675,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 23  (0.0):  46%|████▌     | 23/50 [03:37<04:10,  9.28s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:27] #> Loading codec...\n",
      "[May 13, 02:22:27] #> Loading IVF...\n",
      "[May 13, 02:22:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1076.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who did Lizzette Reynolds fire to make her notable in November 2007?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2106, 9056, 4371, 4674, 9579, 2543, 2000, 2191, 2014,\n",
      "        3862, 1999, 2281, 2289, 1029,  102,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 24  (0.0):  48%|████▊     | 24/50 [03:46<03:59,  9.20s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:36] #> Loading codec...\n",
      "[May 13, 02:22:36] #> Loading IVF...\n",
      "[May 13, 02:22:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 754.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What was the name of the man, who was billed by the coiner of the phrase \"There's a sucker born every minute\" as \"Boy Lightning Calculator\"?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([35]), tensor([  101,     1,  2054,  2001,  1996,  2171,  1997,  1996,  2158,  1010,\n",
      "         2040,  2001, 14843,  2011,  1996,  9226,  2121,  1997,  1996,  7655,\n",
      "         1000,  2045,  1005,  1055,  1037, 26476,  2141,  2296,  3371,  1000,\n",
      "         2004,  1000,  2879,  7407,   102])\n",
      "#> Output Mask: torch.Size([35]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 25  (0.0):  50%|█████     | 25/50 [03:54<03:44,  8.97s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:44] #> Loading codec...\n",
      "[May 13, 02:22:44] #> Loading IVF...\n",
      "[May 13, 02:22:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1131.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which battle was fought for a shorter period of time, the Battle of the Ch'ongch'on River, or the Meuse-Argonne Offensive?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2645,  2001,  4061,  2005,  1037,  7820,  2558,\n",
      "         1997,  2051,  1010,  1996,  2645,  1997,  1996, 10381,  1005,  2006,\n",
      "        18195,  2232,  1005,  2006,  2314,  1010,  2030,  1996,  2033,  8557,\n",
      "         1011,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 26  (0.0):  52%|█████▏    | 26/50 [04:05<03:50,  9.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:22:55] #> Loading codec...\n",
      "[May 13, 02:22:55] #> Loading IVF...\n",
      "[May 13, 02:22:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1054.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:22:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What cricketeer active 1974–1993 had a strong performance in the tour by the Australian cricket team in England in 1981?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4533, 11510,  3161,  3326,  1516,  2857,  2018,\n",
      "         1037,  2844,  2836,  1999,  1996,  2778,  2011,  1996,  2827,  4533,\n",
      "         2136,  1999,  2563,  1999,  3261,  1029,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 27  (0.0):  54%|█████▍    | 27/50 [04:13<03:29,  9.09s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:03] #> Loading codec...\n",
      "[May 13, 02:23:03] #> Loading IVF...\n",
      "[May 13, 02:23:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1266.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the present post of the head coach of the 1982 NC State Wolfpack football team ?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2556,  2695,  1997,  1996,  2132,\n",
      "         2873,  1997,  1996,  3196, 13316,  2110,  4702, 23947,  2374,  2136,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 28  (0.0):  56%|█████▌    | 28/50 [04:25<03:37,  9.87s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:15] #> Loading codec...\n",
      "[May 13, 02:23:15] #> Loading IVF...\n",
      "[May 13, 02:23:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1581.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which Scottish actor sang \"Come What May\"?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2029, 4104, 3364, 6369, 1000, 2272, 2054, 2089, 1000, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 29  (0.0):  58%|█████▊    | 29/50 [04:33<03:14,  9.27s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:23] #> Loading codec...\n",
      "[May 13, 02:23:23] #> Loading IVF...\n",
      "[May 13, 02:23:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1249.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Where have Ivan Bella and Frank De Winne both traveled?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2073,  2031,  7332, 12101,  1998,  3581,  2139,  2663,\n",
      "         2638,  2119,  6158,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 30  (0.0):  60%|██████    | 30/50 [04:42<03:02,  9.14s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:32] #> Loading codec...\n",
      "[May 13, 02:23:32] #> Loading IVF...\n",
      "[May 13, 02:23:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 870.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . The original work by Anton Chekhov involving a disillusioned schoolmaster, which inspired a later play by this British playwright, was written specifically for whom?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1996,  2434,  2147,  2011,  9865, 18178, 25495,  5994,\n",
      "         1037,  4487, 27572, 24117,  2098,  2082,  8706,  1010,  2029,  4427,\n",
      "         1037,  2101,  2377,  2011,  2023,  2329, 11170,  1010,  2001,  2517,\n",
      "         4919,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 31  (0.0):  62%|██████▏   | 31/50 [04:51<02:53,  9.15s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:42] #> Loading codec...\n",
      "[May 13, 02:23:42] #> Loading IVF...\n",
      "[May 13, 02:23:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 963.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are Roswell International Air Center and Pago Pago International Airport both located in the mainland US?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024, 20996, 19228,  2248,  2250,  2415,  1998,  6643,\n",
      "         3995,  6643,  3995,  2248,  3199,  2119,  2284,  1999,  1996,  8240,\n",
      "         2149,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 32  (0.0):  64%|██████▍   | 32/50 [05:00<02:46,  9.26s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:51] #> Loading codec...\n",
      "[May 13, 02:23:51] #> Loading IVF...\n",
      "[May 13, 02:23:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1040.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Untold: The Greatest Sports Stories Never Told was hosted by a sportscaster commonly referred to as what ?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 19662,  6392,  1024,  1996,  4602,  2998,  3441,  2196,\n",
      "         2409,  2001,  4354,  2011,  1037,  2998, 25490,  4141,  3615,  2000,\n",
      "         2004,  2054,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 33  (0.0):  66%|██████▌   | 33/50 [05:08<02:27,  8.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:23:58] #> Loading codec...\n",
      "[May 13, 02:23:58] #> Loading IVF...\n",
      "[May 13, 02:23:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3148.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:23:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are Walt Disney and Sacro GRA both documentry films?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024, 10598,  6373,  1998, 17266,  3217, 24665,  2050,\n",
      "         2119,  6254,  2854,  3152,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 34  (0.0):  68%|██████▊   | 34/50 [05:18<02:27,  9.22s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:08] #> Loading codec...\n",
      "[May 13, 02:24:08] #> Loading IVF...\n",
      "[May 13, 02:24:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1602.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the Palestinian Islamic organization that governs th small territory on the eastern coast of the Mediterranean Sea that was captured by Israel during the 1967 Six-Day War?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([39]), tensor([  101,     1,  2054,  2003,  1996,  9302,  5499,  3029,  2008, 21208,\n",
      "         2015, 16215,  2235,  3700,  2006,  1996,  2789,  3023,  1997,  1996,\n",
      "         7095,  2712,  2008,  2001,  4110,  2011,  3956,  2076,  1996,  3476,\n",
      "         2416,  1011,  2154,  2162,  1029,   102,   103,   103,   103])\n",
      "#> Output Mask: torch.Size([39]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 35  (0.0):  70%|███████   | 35/50 [05:26<02:09,  8.64s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:16] #> Loading codec...\n",
      "[May 13, 02:24:16] #> Loading IVF...\n",
      "[May 13, 02:24:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1487.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What album did the song of which Taylor Swift premiered the music video of during the pre-show of the 2015 MTV Video Music Awards come from?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([35]), tensor([ 101,    1, 2054, 2201, 2106, 1996, 2299, 1997, 2029, 4202, 9170, 5885,\n",
      "        1996, 2189, 2678, 1997, 2076, 1996, 3653, 1011, 2265, 1997, 1996, 2325,\n",
      "        8692, 2678, 2189, 2982, 2272, 2013, 1029,  102,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([35]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 36  (0.0):  72%|███████▏  | 36/50 [05:33<01:55,  8.27s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:23] #> Loading codec...\n",
      "[May 13, 02:24:23] #> Loading IVF...\n",
      "[May 13, 02:24:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2208.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which is considered a genus level classification, Apera or Gunnera manicata?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2003,  2641,  1037,  3562,  2504,  5579,  1010,\n",
      "        23957,  2527,  2030, 14850,  2050, 23624, 11266,  2050,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 37  (0.0):  74%|███████▍  | 37/50 [05:40<01:41,  7.83s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:30] #> Loading codec...\n",
      "[May 13, 02:24:30] #> Loading IVF...\n",
      "[May 13, 02:24:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 855.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Do The Drums and Pussy Galore play music of similar genres?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2079,  1996,  3846,  1998, 22418, 14891,  5686,  2377,\n",
      "         2189,  1997,  2714, 11541,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 38  (0.0):  76%|███████▌  | 38/50 [05:52<01:50,  9.22s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:42] #> Loading codec...\n",
      "[May 13, 02:24:42] #> Loading IVF...\n",
      "[May 13, 02:24:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4485.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the post-nominal abbreviation for the university where the Banded Mongoose Research Project is based?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2695,  1011, 15087, 22498,  2005,\n",
      "         1996,  2118,  2073,  1996, 25264, 12256,  3995,  9232,  2470,  2622,\n",
      "         2003,  2241,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 39  (0.0):  78%|███████▊  | 39/50 [06:00<01:37,  8.90s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:50] #> Loading codec...\n",
      "[May 13, 02:24:50] #> Loading IVF...\n",
      "[May 13, 02:24:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1100.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:24:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are both Benjamin Christensen and Len Wiseman directors?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024,  2119,  6425, 24189,  1998, 18798,  7968,  2386,\n",
      "         5501,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 40  (0.0):  80%|████████  | 40/50 [06:10<01:29,  8.97s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:24:59] #> Loading codec...\n",
      "[May 13, 02:24:59] #> Loading IVF...\n",
      "[May 13, 02:24:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2674.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Steven Cuitlahuac Melendez and Disney are connected by what American animator?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  7112, 12731,  4183, 14431,  6692,  2278, 11463, 28787,\n",
      "         1998,  6373,  2024,  4198,  2011,  2054,  2137, 25132,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 41  (0.0):  82%|████████▏ | 41/50 [06:19<01:21,  9.05s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:25:09] #> Loading codec...\n",
      "[May 13, 02:25:09] #> Loading IVF...\n",
      "[May 13, 02:25:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1268.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Shark Creek is located on this river which is in the northern rivers district?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 11420,  3636,  2003,  2284,  2006,  2023,  2314,  2029,\n",
      "         2003,  1999,  1996,  2642,  5485,  2212,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 42  (0.0):  84%|████████▍ | 42/50 [06:27<01:11,  8.96s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:25:18] #> Loading codec...\n",
      "[May 13, 02:25:18] #> Loading IVF...\n",
      "[May 13, 02:25:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 919.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who was the producer of the 2016 animated film about an amnesiac fish?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  1996,  3135,  1997,  1996,  2355,  6579,\n",
      "         2143,  2055,  2019, 29222,  2278,  3869,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 43  (0.0):  86%|████████▌ | 43/50 [06:35<00:59,  8.50s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:25:25] #> Loading codec...\n",
      "[May 13, 02:25:25] #> Loading IVF...\n",
      "[May 13, 02:25:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 909.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  4156,  1996,  2136,  2745, 22253,  8255,  2005,\n",
      "         1999,  1996,  2786, 14497,  2882,  5431,  1999,  2456,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 44  (0.0):  88%|████████▊ | 44/50 [06:42<00:49,  8.19s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:25:32] #> Loading codec...\n",
      "[May 13, 02:25:32] #> Loading IVF...\n",
      "[May 13, 02:25:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1099.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Fredrick Law Olmsted was an American landscape architect, journalist, social critic and public administrator that designed what neighborhood in Trenton, New Jersey?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  5965, 11285,  2375, 19330,  5244,  3064,  2001,  2019,\n",
      "         2137,  5957,  4944,  1010,  4988,  1010,  2591,  6232,  1998,  2270,\n",
      "         8911,  2008,  2881,  2054,  5101,  1999, 17148,  1010,  2047,  3933,\n",
      "         1029,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 45  (0.0):  90%|█████████ | 45/50 [06:51<00:40,  8.19s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:25:41] #> Loading codec...\n",
      "[May 13, 02:25:41] #> Loading IVF...\n",
      "[May 13, 02:25:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1007.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:25:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Gordon Warnecke worked alongside the former senator for which political party on Young Toscanini?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  5146, 11582, 11012,  2063,  2499,  4077,  1996,  2280,\n",
      "         5205,  2005,  2029,  2576,  2283,  2006,  2402,  2000, 29378,  5498,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 46  (0.0):  92%|█████████▏| 46/50 [07:16<00:53, 13.30s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:26:06] #> Loading codec...\n",
      "[May 13, 02:26:06] #> Loading IVF...\n",
      "[May 13, 02:26:06] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3964.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:26:06] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . André Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  7213, 16950, 16665,  2001,  1037,  2413,  8088,  2040,\n",
      "         2499,  2007,  1037,  2446, 10398,  2932,  2405,  2011,  2054,  6394,\n",
      "         3029,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 47  (0.0):  94%|█████████▍| 47/50 [07:26<00:36, 12.31s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:26:16] #> Loading codec...\n",
      "[May 13, 02:26:16] #> Loading IVF...\n",
      "[May 13, 02:26:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 794.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:26:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Both Bill Ponsford and Bill Woodfull played what?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2119,  3021, 13433,  3619,  3877,  1998,  3021,  3536,\n",
      "         3993,  2140,  2209,  2054,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 48  (0.0):  96%|█████████▌| 48/50 [07:35<00:22, 11.43s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:26:25] #> Loading codec...\n",
      "[May 13, 02:26:25] #> Loading IVF...\n",
      "[May 13, 02:26:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3266.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:26:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: .  Suzana S. Drobnjaković Ponti acted in a film loosely based on a book by who?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10514, 13471,  2050,  1055,  1012,  2852, 16429,  2078,\n",
      "        18317,  9142, 21179,  2072,  6051,  1999,  1037,  2143, 11853,  2241,\n",
      "         2006,  1037,  2338,  2011,  2040,  1029,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 49  (0.0):  98%|█████████▊| 49/50 [07:46<00:11, 11.30s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:26:36] #> Loading codec...\n",
      "[May 13, 02:26:36] #> Loading IVF...\n",
      "[May 13, 02:26:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3315.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:26:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . In what city was the Election Law Journal founded?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1999, 2054, 2103, 2001, 1996, 2602, 2375, 3485, 2631, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 50  (0.0): 100%|██████████| 50/50 [07:54<00:00,  9.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b9446 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b9446 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b9446_row0_col0, #T_b9446_row0_col1, #T_b9446_row0_col2, #T_b9446_row0_col3, #T_b9446_row0_col4, #T_b9446_row0_col5, #T_b9446_row1_col0, #T_b9446_row1_col1, #T_b9446_row1_col2, #T_b9446_row1_col3, #T_b9446_row1_col4, #T_b9446_row1_col5, #T_b9446_row2_col0, #T_b9446_row2_col1, #T_b9446_row2_col2, #T_b9446_row2_col3, #T_b9446_row2_col4, #T_b9446_row2_col5, #T_b9446_row3_col0, #T_b9446_row3_col1, #T_b9446_row3_col2, #T_b9446_row3_col3, #T_b9446_row3_col4, #T_b9446_row3_col5, #T_b9446_row4_col0, #T_b9446_row4_col1, #T_b9446_row4_col2, #T_b9446_row4_col3, #T_b9446_row4_col4, #T_b9446_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b9446\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b9446_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_b9446_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_b9446_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_b9446_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_b9446_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_b9446_level0_col5\" class=\"col_heading level0 col5\" >gold_passages_retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b9446_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b9446_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_b9446_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_b9446_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_b9446_row0_col3\" class=\"data row0 col3\" >[\"Shenzhen Peng City (2019–present)\\nOn 20 February 2019, it was announced that CFG as well as UBTECH and China Sports Capital had acquired Sichuan Jiuniu F.C.\\n...</td>\n",
       "      <td id=\"T_b9446_row0_col4\" class=\"data row0 col4\" >No. Cangzhou is in Hebei province, while Qionghai is in Hainan province.</td>\n",
       "      <td id=\"T_b9446_row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9446_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b9446_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_b9446_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_b9446_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_b9446_row1_col3\" class=\"data row1 col3\" >[\"It restored its sponsorship after the change of ownership of the club.\\nFollowing the introduction of sleeve sponsors in the Premier League, Chelsea had Alliance Tyres...</td>\n",
       "      <td id=\"T_b9446_row1_col4\" class=\"data row1 col4\" >National Hockey League (NHL)</td>\n",
       "      <td id=\"T_b9446_row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9446_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b9446_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_b9446_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_b9446_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_b9446_row2_col3\" class=\"data row2 col3\" >[\"In his 21st and final season, Arsenal under Arsene Wenger finished sixth and won the community shield. Wenger departed Arsenal following the end of the...</td>\n",
       "      <td id=\"T_b9446_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_b9446_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9446_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b9446_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_b9446_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_b9446_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_b9446_row3_col3\" class=\"data row3 col3\" >[\"A new training ground was constructed at the site for £45 million, which opened in 2012. The 77-acre site has 15 grass pitches and one-and-a-half...</td>\n",
       "      <td id=\"T_b9446_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_b9446_row3_col5\" class=\"data row3 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9446_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b9446_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_b9446_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_b9446_row4_col2\" class=\"data row4 col2\" >{'Ealhswith', 'Æthelweard (son of Alfred)'}</td>\n",
       "      <td id=\"T_b9446_row4_col3\" class=\"data row4 col3\" >['== Crest ==\\n\\nSince the 1921 FA Cup Final the Tottenham Hotspur crest has featured a cockerel. Harry Hotspur, after whom the club is named, was...</td>\n",
       "      <td id=\"T_b9446_row4_col4\" class=\"data row4 col4\" >Alfred the Great</td>\n",
       "      <td id=\"T_b9446_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f01f7131c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gold_passages_retrieved(example, pred, trace=None):\n",
    "    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n",
    "    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n",
    "    return gold_titles.issubset(found_titles)\n",
    "\n",
    "evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "compiled_rag_retrieval_score = evaluate_on_hotpotqa(compiled_rag, metric=gold_passages_retrieved)\n",
    "\n",
    "# 5b. Uncompiled Baleen RAG (without Optimizer)\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "class SimplifiedBaleen(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            #passages = self.retrieve(query).passages\n",
    "            context_dict = query_index(query=query, topk=3)\n",
    "            passages = [x['content'] for x in context_dict]\n",
    "            context = deduplicate(context + passages)\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:27:53] #> Loading codec...\n",
      "[May 13, 02:27:53] #> Loading IVF...\n",
      "[May 13, 02:27:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1462.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:27:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"longest unbeaten run in Premier League history by a club\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  6493, 20458,  2448,  1999,  4239,  2223,  2381,\n",
      "         2011,  1037,  2252,  1000,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:28:02] #> Loading codec...\n",
      "[May 13, 02:28:02] #> Loading IVF...\n",
      "[May 13, 02:28:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1596.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:28:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Which football club holds the record for the longest unbeaten run in the Premier League?\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2029,  2374,  2252,  4324,  1996,  2501,  2005,\n",
      "         1996,  6493, 20458,  2448,  1999,  1996,  4239,  2223,  1029,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\n",
    "pred = uncompiled_baleen(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Which club has the record for the longest unbeaten run in the premier league?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Which club has the record for the longest unbeaten run in the premier league?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicted Answer: Arsenal\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Predicted Answer: Arsenal\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Contexts <span style=\"font-weight: bold\">(</span>truncated<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Arsenal hold the record for the longest run of unbeaten League matches (49 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between May 2003 and October 2004). This included all 38 matches of their title-winning 2003–04 season, when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arsenal became o...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">period in the 1930s. He helped introduce the WM formation, floodlights, and shirt numbers; he also added the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">wh...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Chelsea hold the English record for the fewest goals conceded during a league season (15), the highest </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of clean sheets overall in a Premier League season (25) (both set during the 2004–05 seaso...'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Contexts \u001b[1m(\u001b[0mtruncated\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Arsenal hold the record for the longest run of unbeaten League matches \u001b[0m\u001b[32m(\u001b[0m\u001b[32m49 \u001b[0m\n",
       "\u001b[32mbetween May 2003 and October 2004\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This included all 38 matches of their title-winning 2003–04 season, when \u001b[0m\n",
       "\u001b[32mArsenal became o...'\u001b[0m, \u001b[32m'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden \u001b[0m\n",
       "\u001b[32mperiod in the 1930s. He helped introduce the WM formation, floodlights, and shirt numbers; he also added the \u001b[0m\n",
       "\u001b[32mwh...'\u001b[0m, \u001b[32m'Chelsea hold the English record for the fewest goals conceded during a league season \u001b[0m\u001b[32m(\u001b[0m\u001b[32m15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the highest \u001b[0m\n",
       "\u001b[32mnumber of clean sheets overall in a Premier League season \u001b[0m\u001b[32m(\u001b[0m\u001b[32m25\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mboth set during the 2004–05 seaso...'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Question: {query}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiled Baleen RAG with Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c. Compiled Baleen RAG (with Optimizer)\n",
    "def validate_context_and_answer_and_hops(example, pred, trace=None):\n",
    "    if not dspy.evaluate.answer_exact_match(example, pred): return False\n",
    "    if not dspy.evaluate.answer_passage_match(example, pred): return False\n",
    "    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n",
    "    if max([len(h) for h in hops]) > 100: return False\n",
    "    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:19] #> Loading codec...\n",
      "[May 13, 02:39:19] #> Loading IVF...\n",
      "[May 13, 02:39:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 949.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"At My Window\" artist singer-songwriter released, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2012, 2026, 3332, 1000, 3063, 3220, 1011, 6009, 2207,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:24] #> Loading codec...\n",
      "[May 13, 02:39:24] #> Loading IVF...\n",
      "[May 13, 02:39:24] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1227.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:24] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . List of songs in the UK Singles Chart around the same time as \"Blue Tomorrow\" by Chelsea., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2862, 1997, 2774, 1999, 1996, 2866, 3895, 3673, 2105, 1996,\n",
      "        2168, 2051, 2004, 1000, 2630, 4826, 1000, 2011, 9295, 1012,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:28] #> Loading codec...\n",
      "[May 13, 02:39:28] #> Loading IVF...\n",
      "[May 13, 02:39:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1361.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Candace Kita guest starred with which American actor?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 22905,  8934,  2050,  4113,  5652,  2007,  2029,  2137,\n",
      "         3364,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:32] #> Loading codec...\n",
      "[May 13, 02:39:32] #> Loading IVF...\n",
      "[May 13, 02:39:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1132.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Cast of \"Jhoom Barabar Jhoom\" film, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3459,  1997,  1000,  1046,  6806,  5358,  3347, 19736,\n",
      "         2099,  1046,  6806,  5358,  1000,  2143,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:36] #> Loading codec...\n",
      "[May 13, 02:39:36] #> Loading IVF...\n",
      "[May 13, 02:39:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 864.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"publication date of Who Put the Bomp\" OR \"publication date of Self\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4772, 3058, 1997, 2040, 2404, 1996, 8945, 8737, 1000,\n",
      "        2030, 1000, 4772, 3058, 1997, 2969, 1000,  102,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:41] #> Loading codec...\n",
      "[May 13, 02:39:41] #> Loading IVF...\n",
      "[May 13, 02:39:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1005.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Who Put the Bomp\" publication date site:goodreads.com OR \"Self\" publication date site:goodreads.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2040,  2404,  1996,  8945,  8737,  1000,  4772,\n",
      "         3058,  2609,  1024,  2204, 16416,  5104,  1012,  4012,  2030,  1000,\n",
      "         2969,  1000,  4772,  3058,  2609,  1024,  2204, 16416,  5104,  1012,\n",
      "         4012,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:45] #> Loading codec...\n",
      "[May 13, 02:39:45] #> Loading IVF...\n",
      "[May 13, 02:39:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1227.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"The Victorians - Their Story In Pictures documentary series release date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 1996, 6652, 2015, 1011, 2037, 2466, 1999, 4620, 4516,\n",
      "        2186, 2713, 3058, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:49] #> Loading codec...\n",
      "[May 13, 02:39:49] #> Loading IVF...\n",
      "[May 13, 02:39:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 2318.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"The Victorians - Their Story In Pictures\" author birth year site:imdb.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  1996,  6652,  2015,  1011,  2037,  2466,  1999,\n",
      "         4620,  1000,  3166,  4182,  2095,  2609,  1024, 10047, 18939,  1012,\n",
      "         4012,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:53] #> Loading codec...\n",
      "[May 13, 02:39:53] #> Loading IVF...\n",
      "[May 13, 02:39:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1013.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Scott Shaw articles site:taekwondotimes.com\" OR \"Scott Shaw articles site:southwestart.com\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3660,  8233,  4790,  2609,  1024, 28529,  7292,\n",
      "         2015,  1012,  4012,  1000,  2030,  1000,  3660,  8233,  4790,  2609,\n",
      "         1024,  4943,  8445,  1012,  4012,  1000,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:39:58] #> Loading codec...\n",
      "[May 13, 02:39:58] #> Loading IVF...\n",
      "[May 13, 02:39:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 570.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:39:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Scott Shaw articles site:taekwondotimes.com\" OR \"Scott Shaw articles site:southwestart.com\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3660,  8233,  4790,  2609,  1024, 28529,  7292,\n",
      "         2015,  1012,  4012,  1000,  2030,  1000,  3660,  8233,  4790,  2609,\n",
      "         1024,  4943,  8445,  1012,  4012,  1000,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:03] #> Loading codec...\n",
      "[May 13, 02:40:03] #> Loading IVF...\n",
      "[May 13, 02:40:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 897.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"founding year of [opposing club] football club\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4889,  2095,  1997,  1031, 10078,  2252,  1033,\n",
      "         2374,  2252,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:09] #> Loading codec...\n",
      "[May 13, 02:40:09] #> Loading IVF...\n",
      "[May 13, 02:40:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1025.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"founding year of Manchester City's 1972 FA Charity Shield opponent\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4889, 2095, 1997, 5087, 2103, 1005, 1055, 3285, 6904,\n",
      "        5952, 6099, 7116, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:13] #> Loading codec...\n",
      "[May 13, 02:40:13] #> Loading IVF...\n",
      "[May 13, 02:40:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 846.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"height of Empire State Building\" OR \"height of Bank of America Tower\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4578, 1997, 3400, 2110, 2311, 1000, 2030, 1000, 4578,\n",
      "        1997, 2924, 1997, 2637, 3578, 1000,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:18] #> Loading codec...\n",
      "[May 13, 02:40:18] #> Loading IVF...\n",
      "[May 13, 02:40:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 2629.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Height of Empire State Building\" vs \"Height of Bank of America Tower\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4578, 1997, 3400, 2110, 2311, 1000, 5443, 1000, 4578,\n",
      "        1997, 2924, 1997, 2637, 3578, 1000,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:22] #> Loading codec...\n",
      "[May 13, 02:40:22] #> Loading IVF...\n",
      "[May 13, 02:40:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1631.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"American actress film debut 1995 Kids co-founder Voto Latino\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2137,  3883,  2143,  2834,  2786,  4268,  2522,\n",
      "         1011,  3910, 29536,  3406,  7402,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:26] #> Loading codec...\n",
      "[May 13, 02:40:26] #> Loading IVF...\n",
      "[May 13, 02:40:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1223.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American actress film debut 1995 \"Kids\" co-founder Voto Latino, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137,  3883,  2143,  2834,  2786,  1000,  4268,  1000,\n",
      "         2522,  1011,  3910, 29536,  3406,  7402,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:30] #> Loading codec...\n",
      "[May 13, 02:40:30] #> Loading IVF...\n",
      "[May 13, 02:40:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 993.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Actor born May 17, 1955 in Tombstone movie\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3364,  2141,  2089,  2459,  1010,  3982,  1999,\n",
      "        26671,  3185,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:35] #> Loading codec...\n",
      "[May 13, 02:40:35] #> Loading IVF...\n",
      "[May 13, 02:40:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1038.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Actor born May 17, 1955 Tombstone movie cast, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3364,  2141,  2089,  2459,  1010,  3982, 26671,  3185,\n",
      "         3459,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:39] #> Loading codec...\n",
      "[May 13, 02:40:39] #> Loading IVF...\n",
      "[May 13, 02:40:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1878.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Operation Typhoon 102nd Infantry Division\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3169, 15393,  9402,  4859,  3939,  2407,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:44] #> Loading codec...\n",
      "[May 13, 02:40:44] #> Loading IVF...\n",
      "[May 13, 02:40:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1137.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . German offensive 102nd Infantry Division code name Eastern Front World War II, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2446, 5805, 9402, 4859, 3939, 2407, 3642, 2171, 2789, 2392,\n",
      "        2088, 2162, 2462,  102,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:48] #> Loading codec...\n",
      "[May 13, 02:40:48] #> Loading IVF...\n",
      "[May 13, 02:40:48] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1286.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:48] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"The Shore\" film cast + youngest actress to play Ophelia in Royal Shakespeare Company \"Hamlet\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  1996,  5370,  1000,  2143,  3459,  1009,  6587,\n",
      "         3883,  2000,  2377,  6728, 16001,  2401,  1999,  2548,  8101,  2194,\n",
      "         1000,  8429,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:53] #> Loading codec...\n",
      "[May 13, 02:40:53] #> Loading IVF...\n",
      "[May 13, 02:40:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1248.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Actress in The Shore AND youngest actress to play Ophelia in Royal Shakespeare Company \"Hamlet\" production, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3883,  1999,  1996,  5370,  1998,  6587,  3883,  2000,\n",
      "         2377,  6728, 16001,  2401,  1999,  2548,  8101,  2194,  1000,  8429,\n",
      "         1000,  2537,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:40:57] #> Loading codec...\n",
      "[May 13, 02:40:57] #> Loading IVF...\n",
      "[May 13, 02:40:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1491.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:40:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"1977 American animated film Sherman Brothers songs\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3355,  2137,  6579,  2143, 11011,  3428,  2774,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:01] #> Loading codec...\n",
      "[May 13, 02:41:01] #> Loading IVF...\n",
      "[May 13, 02:41:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3243.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"1977 American animated film Sherman Brothers songs distribution company\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3355,  2137,  6579,  2143, 11011,  3428,  2774,\n",
      "         4353,  2194,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:05] #> Loading codec...\n",
      "[May 13, 02:41:05] #> Loading IVF...\n",
      "[May 13, 02:41:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1089.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Samantha Cristoforetti first space mission\" AND \"Mark Shuttleworth first space mission\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 11415, 13675, 20483, 29278, 18319,  2034,  2686,\n",
      "         3260,  1000,  1998,  1000,  2928, 10382,  5172,  2034,  2686,  3260,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:10] #> Loading codec...\n",
      "[May 13, 02:41:10] #> Loading IVF...\n",
      "[May 13, 02:41:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 963.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"first person to brew espresso in space\" OR \"first African in space\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2034,  2711,  2000, 24702,  9686, 20110,  2080,\n",
      "         1999,  2686,  1000,  2030,  1000,  2034,  3060,  1999,  2686,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:14] #> Loading codec...\n",
      "[May 13, 02:41:14] #> Loading IVF...\n",
      "[May 13, 02:41:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 906.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Eric Davis outfield performance Los Angeles Dodgers foot speed bat speed\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4388,  4482,  2041,  3790,  2836,  3050,  3349,\n",
      "        13391,  3329,  3177,  7151,  3177,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:19] #> Loading codec...\n",
      "[May 13, 02:41:19] #> Loading IVF...\n",
      "[May 13, 02:41:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 2343.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Eric Davis Los Angeles Dodgers outfield performance foot speed bat speed\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4388,  4482,  3050,  3349, 13391,  2041,  3790,\n",
      "         2836,  3329,  3177,  7151,  3177,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:24] #> Loading codec...\n",
      "[May 13, 02:41:24] #> Loading IVF...\n",
      "[May 13, 02:41:24] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3518.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:24] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Aleem Dar ICC World Twenty20 umpire 2021\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 15669,  6633, 18243, 16461,  2088, 22240, 20887,\n",
      "        25682,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:28] #> Loading codec...\n",
      "[May 13, 02:41:28] #> Loading IVF...\n",
      "[May 13, 02:41:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 2853.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Pakistani cricket umpire ICC World Twenty20 2022, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9889,  4533, 20887, 16461,  2088, 22240, 16798,  2475,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:33] #> Loading codec...\n",
      "[May 13, 02:41:33] #> Loading IVF...\n",
      "[May 13, 02:41:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 2933.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Organization name founded year\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 3029, 2171, 2631, 2095, 1000,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:38] #> Loading codec...\n",
      "[May 13, 02:41:38] #> Loading IVF...\n",
      "[May 13, 02:41:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1071.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"founding year of Tottenham Hotspur Women\" OR \"founding year of Chelsea F.C.\" OR \"founding year of Manchester United Football Club\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4889,  2095,  1997, 18127, 25985,  2308,  1000,\n",
      "         2030,  1000,  4889,  2095,  1997,  9295,  1042,  1012,  1039,  1012,\n",
      "         1000,  2030,  1000,  4889,  2095,  1997,  5087,  2142,  2374,  2252,\n",
      "         1000,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:41] #> Loading codec...\n",
      "[May 13, 02:41:41] #> Loading IVF...\n",
      "[May 13, 02:41:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3123.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Everything Has Changed\" album record label [artist name], \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2673, 2038, 2904, 1000, 2201, 2501, 3830, 1031, 3063,\n",
      "        2171, 1033,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:46] #> Loading codec...\n",
      "[May 13, 02:41:46] #> Loading IVF...\n",
      "[May 13, 02:41:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Everything Has Changed\" album record label site:wikipedia.org, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2673,  2038,  2904,  1000,  2201,  2501,  3830,\n",
      "         2609,  1024, 16948,  1012,  8917,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:52] #> Loading codec...\n",
      "[May 13, 02:41:52] #> Loading IVF...\n",
      "[May 13, 02:41:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3026.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Aleksandr Danilovich Aleksandrov birth date\" AND \"Anatoly Fomenko birth date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 24020, 19522, 29356,  2232, 24020,  4492,  4182,\n",
      "         3058,  1000,  1998,  1000,  9617,  3406,  2135,  1042,  8462, 16107,\n",
      "         4182,  3058,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:41:57] #> Loading codec...\n",
      "[May 13, 02:41:57] #> Loading IVF...\n",
      "[May 13, 02:41:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 587.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:41:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2040,  2003,  3080,  1010, 24020, 19522, 29356,\n",
      "         2232, 24020,  4492,  2030,  9617,  3406,  2135,  1042,  8462, 16107,\n",
      "         1029,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:01] #> Loading codec...\n",
      "[May 13, 02:42:01] #> Loading IVF...\n",
      "[May 13, 02:42:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 4963.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What ocean is Senegal located on?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4153,  2003, 16028,  2284,  2006,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:05] #> Loading codec...\n",
      "[May 13, 02:42:05] #> Loading IVF...\n",
      "[May 13, 02:42:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3826.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Diogal Sakho birthplace ocean, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  4487, 18170,  2140,  7842, 10023,  2080, 14508,  4153,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:09] #> Loading codec...\n",
      "[May 13, 02:42:09] #> Loading IVF...\n",
      "[May 13, 02:42:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3323.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"American guitarist Iron Maidens ancestor composer\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2137,  5990,  3707, 10494,  2015, 13032,  4543,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:13] #> Loading codec...\n",
      "[May 13, 02:42:13] #> Loading IVF...\n",
      "[May 13, 02:42:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 3034.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nita Strauss family composer ancestor name., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9152,  2696, 16423,  2155,  4543, 13032,  2171,  1012,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [02:58<00:00,  8.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:17] #> Loading codec...\n",
      "[May 13, 02:42:17] #> Loading IVF...\n",
      "[May 13, 02:42:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1475.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Cangzhou location province China\" AND \"Qionghai location province China\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2064,  2290,  9791,  3295,  2874,  2859,  1000,\n",
      "         1998,  1000, 18816,  5063, 10932,  3295,  2874,  2859,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:22] #> Loading codec...\n",
      "[May 13, 02:42:22] #> Loading IVF...\n",
      "[May 13, 02:42:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2884.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Cangzhou and Qionghai in China, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997,  2064,  2290,  9791,  1998, 18816,  5063,\n",
      "        10932,  1999,  2859,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0):   2%|▏         | 1/50 [00:08<07:16,  8.91s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:26] #> Loading codec...\n",
      "[May 13, 02:42:26] #> Loading IVF...\n",
      "[May 13, 02:42:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 965.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"2017 NHL Expansion Draft conductors\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2418,  7097,  4935,  4433, 23396,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:32] #> Loading codec...\n",
      "[May 13, 02:42:32] #> Loading IVF...\n",
      "[May 13, 02:42:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3139.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who conducted the NHL draft for the 2017-18 season?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 4146, 1996, 7097, 4433, 2005, 1996, 2418, 1011, 2324,\n",
      "        2161, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   4%|▍         | 2/50 [00:18<07:33,  9.44s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:36] #> Loading codec...\n",
      "[May 13, 02:42:36] #> Loading IVF...\n",
      "[May 13, 02:42:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2281.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Canadian retired professional ice hockey player general manager Tampa Bay Lightning\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 3010, 3394, 2658, 3256, 3873, 2447, 2236, 3208, 9925,\n",
      "        3016, 7407, 1000,  102,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:41] #> Loading codec...\n",
      "[May 13, 02:42:41] #> Loading IVF...\n",
      "[May 13, 02:42:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who is the Canadian retired professional ice hockey player and current general manager of the Tampa Bay Lightning of the National Hockey League (NHL) following the retirement of Steve Yzerman?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([40]), tensor([ 101,    1, 2040, 2003, 1996, 3010, 3394, 2658, 3256, 3873, 2447, 1998,\n",
      "        2783, 2236, 3208, 1997, 1996, 9925, 3016, 7407, 1997, 1996, 2120, 3873,\n",
      "        2223, 1006, 7097, 1007, 2206, 1996, 5075, 1997, 3889, 1061, 6290, 2386,\n",
      "        1029,  102,  103,  103])\n",
      "#> Output Mask: torch.Size([40]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):   6%|▌         | 3/50 [00:28<07:22,  9.42s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:45] #> Loading codec...\n",
      "[May 13, 02:42:45] #> Loading IVF...\n",
      "[May 13, 02:42:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3554.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"town near Crichton Collegiate Church\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2237,  2379, 13675,  7033,  2669,  9234,  2277,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:50] #> Loading codec...\n",
      "[May 13, 02:42:50] #> Loading IVF...\n",
      "[May 13, 02:42:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1255.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Rivers near Crichton Collegiate Church Dumfries Scotland, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  5485,  2379, 13675,  7033,  2669,  9234,  2277,  4241,\n",
      "         2213, 19699,  3111,  3885,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 4  (0.0):   8%|▊         | 4/50 [00:36<06:48,  8.88s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:42:53] #> Loading codec...\n",
      "[May 13, 02:42:53] #> Loading IVF...\n",
      "[May 13, 02:42:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1655.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:42:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Father of Æthelweard son of Ealhswith\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2269,  1997,  1097, 10760,  2140, 16689,  2094,\n",
      "         2365,  1997, 19413,  2140,  7898, 24415,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:00] #> Loading codec...\n",
      "[May 13, 02:43:00] #> Loading IVF...\n",
      "[May 13, 02:43:00] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 988.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who was the father of Æthelweard, son of Ealhswith, in the 10th Century A.D.?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  1996,  2269,  1997,  1097, 10760,  2140,\n",
      "        16689,  2094,  1010,  2365,  1997, 19413,  2140,  7898, 24415,  1010,\n",
      "         1999,  1996,  6049,  2301,  1037,  1012,  1040,  1012,  1029,   102,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 5  (0.0):  10%|█         | 5/50 [00:46<06:59,  9.33s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:04] #> Loading codec...\n",
      "[May 13, 02:43:04] #> Loading IVF...\n",
      "[May 13, 02:43:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4301.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Newark Airport Exchange operator\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 12948,  3199,  3863,  6872,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:08] #> Loading codec...\n",
      "[May 13, 02:43:08] #> Loading IVF...\n",
      "[May 13, 02:43:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1147.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who operates Newark Airport?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  5748, 12948,  3199,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 6  (0.0):  12%|█▏        | 6/50 [00:54<06:32,  8.91s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:12] #> Loading codec...\n",
      "[May 13, 02:43:12] #> Loading IVF...\n",
      "[May 13, 02:43:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2646.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Peruvian footballer goal domestic double win event location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 15432,  4362,  3125,  4968,  3313,  2663,  2724,\n",
      "         3295,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:17] #> Loading codec...\n",
      "[May 13, 02:43:17] #> Loading IVF...\n",
      "[May 13, 02:43:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4583.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Peruvian footballer domestic double win location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 15432,  4362,  4968,  3313,  2663,  3295,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 7  (0.0):  14%|█▍        | 7/50 [01:03<06:21,  8.87s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:20] #> Loading codec...\n",
      "[May 13, 02:43:21] #> Loading IVF...\n",
      "[May 13, 02:43:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2910.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Chico Municipal Airport location\" AND \"William R. Fairchild International Airport location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 22136,  4546,  3199,  3295,  1000,  1998,  1000,\n",
      "         2520,  1054,  1012, 24258,  2248,  3199,  3295,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:25] #> Loading codec...\n",
      "[May 13, 02:43:25] #> Loading IVF...\n",
      "[May 13, 02:43:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1129.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Chico Municipal Airport and William R. Fairchild International Airport, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997, 22136,  4546,  3199,  1998,  2520,  1054,\n",
      "         1012, 24258,  2248,  3199,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 8  (0.0):  16%|█▌        | 8/50 [01:11<06:00,  8.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:29] #> Loading codec...\n",
      "[May 13, 02:43:29] #> Loading IVF...\n",
      "[May 13, 02:43:29] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3079.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:29] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fort Pownall location Maine county\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3481, 23776, 22270,  3295,  7081,  2221,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:33] #> Loading codec...\n",
      "[May 13, 02:43:33] #> Loading IVF...\n",
      "[May 13, 02:43:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1255.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Fort Pownall, Maine county, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997,  3481, 23776, 22270,  1010,  7081,  2221,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 9  (0.0):  18%|█▊        | 9/50 [01:19<05:52,  8.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:37] #> Loading codec...\n",
      "[May 13, 02:43:37] #> Loading IVF...\n",
      "[May 13, 02:43:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3079.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Gene band reunion date\" OR \"The Afghan Whigs band reunion date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4962,  2316, 10301,  3058,  1000,  2030,  1000,\n",
      "         1996, 12632, 21632,  2015,  2316, 10301,  3058,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:42] #> Loading codec...\n",
      "[May 13, 02:43:42] #> Loading IVF...\n",
      "[May 13, 02:43:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2937.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Gene band reunion date\" OR \"The Afghan Whigs band reunion date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4962,  2316, 10301,  3058,  1000,  2030,  1000,\n",
      "         1996, 12632, 21632,  2015,  2316, 10301,  3058,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 10  (0.0):  20%|██        | 10/50 [01:28<05:41,  8.54s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:46] #> Loading codec...\n",
      "[May 13, 02:43:46] #> Loading IVF...\n",
      "[May 13, 02:43:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4332.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Monte Vesuvio eruption date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10125,  2310,  6342, 25500, 17259,  3058,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:51] #> Loading codec...\n",
      "[May 13, 02:43:51] #> Loading IVF...\n",
      "[May 13, 02:43:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3975.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Year of eruption of Mount Vesuvius in Italy., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2095,  1997, 17259,  1997,  4057,  2310,  6342, 26055,\n",
      "         1999,  3304,  1012,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 11  (0.0):  22%|██▏       | 11/50 [01:36<05:33,  8.56s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:54] #> Loading codec...\n",
      "[May 13, 02:43:54] #> Loading IVF...\n",
      "[May 13, 02:43:54] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1030.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:54] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Establishment date of 72nd field brigade\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 5069, 3058, 1997, 5824, 4859, 2492, 4250, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:43:59] #> Loading codec...\n",
      "[May 13, 02:43:59] #> Loading IVF...\n",
      "[May 13, 02:43:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:43:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Establishment date of 72nd field brigade\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 5069, 3058, 1997, 5824, 4859, 2492, 4250, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 12  (0.0):  24%|██▍       | 12/50 [01:45<05:21,  8.46s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:02] #> Loading codec...\n",
      "[May 13, 02:44:02] #> Loading IVF...\n",
      "[May 13, 02:44:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1176.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Stanislaw Kiszka payment Royal Treasury\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9761,  2483, 14919, 11382, 17112,  2912,  7909,\n",
      "         2548,  9837,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:08] #> Loading codec...\n",
      "[May 13, 02:44:08] #> Loading IVF...\n",
      "[May 13, 02:44:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3560.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Stanislaw Kiszka payment Royal Treasury\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9761,  2483, 14919, 11382, 17112,  2912,  7909,\n",
      "         2548,  9837,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 13  (0.0):  26%|██▌       | 13/50 [01:54<05:20,  8.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:12] #> Loading codec...\n",
      "[May 13, 02:44:12] #> Loading IVF...\n",
      "[May 13, 02:44:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3256.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Del Lord birthdate\" OR \"Wang Xiaoshuai birthdate\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3972,  2935,  4182, 13701,  1000,  2030,  1000,\n",
      "         7418, 19523, 14235,  4886,  4182, 13701,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:17] #> Loading codec...\n",
      "[May 13, 02:44:17] #> Loading IVF...\n",
      "[May 13, 02:44:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4957.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Del Lord birth date\" AND \"Wang Xiaoshuai birth date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3972,  2935,  4182,  3058,  1000,  1998,  1000,\n",
      "         7418, 19523, 14235,  4886,  4182,  3058,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 14  (0.0):  28%|██▊       | 14/50 [02:02<05:12,  8.67s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:20] #> Loading codec...\n",
      "[May 13, 02:44:20] #> Loading IVF...\n",
      "[May 13, 02:44:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1475.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Former Conservative MP perjury 1999 site:Lord North Street\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2280, 4603, 6131, 2566, 9103, 2854, 2639, 2609, 1024,\n",
      "        2935, 2167, 2395, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:24] #> Loading codec...\n",
      "[May 13, 02:44:24] #> Loading IVF...\n",
      "[May 13, 02:44:24] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1406.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Residents of Lord North Street London, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 3901, 1997, 2935, 2167, 2395, 2414,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 15  (0.0):  30%|███       | 15/50 [02:11<05:00,  8.57s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:28] #> Loading codec...\n",
      "[May 13, 02:44:28] #> Loading IVF...\n",
      "[May 13, 02:44:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3912.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Name of Marche region Italy, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2171,  1997, 28791,  2555,  3304,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:33] #> Loading codec...\n",
      "[May 13, 02:44:33] #> Loading IVF...\n",
      "[May 13, 02:44:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1396.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What region of Italy includes the March of Ancona, Camerino, and Fermo?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2555,  1997,  3304,  2950,  1996,  2233,  1997,\n",
      "         2019, 24366,  1010,  2234, 17815,  1010,  1998, 10768, 10867,  2080,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 16  (0.0):  32%|███▏      | 16/50 [02:19<04:49,  8.52s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:37] #> Loading codec...\n",
      "[May 13, 02:44:37] #> Loading IVF...\n",
      "[May 13, 02:44:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3942.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Population of [city name]\"., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2313, 1997, 1031, 2103, 2171, 1033, 1000, 1012,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:41] #> Loading codec...\n",
      "[May 13, 02:44:41] #> Loading IVF...\n",
      "[May 13, 02:44:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1784.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Population of Manchester in [year of William Hughes Miller's birth], \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2313, 1997, 5087, 1999, 1031, 2095, 1997, 2520, 8099, 4679,\n",
      "        1005, 1055, 4182, 1033,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 17  (0.0):  34%|███▍      | 17/50 [02:27<04:39,  8.46s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:45] #> Loading codec...\n",
      "[May 13, 02:44:45] #> Loading IVF...\n",
      "[May 13, 02:44:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4410.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"New York University school activities for art students\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2047, 2259, 2118, 2082, 3450, 2005, 2396, 2493, 1000,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:50] #> Loading codec...\n",
      "[May 13, 02:44:50] #> Loading IVF...\n",
      "[May 13, 02:44:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1229.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"New York University Meleko Mokgosi curriculum courses activities\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2047,  2259,  2118, 11463,  5937,  2080,  9587,\n",
      "         2243, 12333,  2072,  8882,  5352,  3450,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 18  (0.0):  36%|███▌      | 18/50 [02:37<04:44,  8.90s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:56] #> Loading codec...\n",
      "[May 13, 02:44:56] #> Loading IVF...\n",
      "[May 13, 02:44:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1399.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Robert Irvine nationality\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2728, 16272, 10662,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:44:59] #> Loading codec...\n",
      "[May 13, 02:44:59] #> Loading IVF...\n",
      "[May 13, 02:44:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:44:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nationality of Robert Irvine chef and restaurateur, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10662,  1997,  2728, 16272, 10026,  1998,  2717, 21159,\n",
      "         3686,  3126,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 19  (0.0):  38%|███▊      | 19/50 [02:45<04:24,  8.54s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:03] #> Loading codec...\n",
      "[May 13, 02:45:03] #> Loading IVF...\n",
      "[May 13, 02:45:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 963.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American actor East side drug lord peaceful solutions site:imdb.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137,  3364,  2264,  2217,  4319,  2935,  9379,  7300,\n",
      "         2609,  1024, 10047, 18939,  1012,  4012,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:08] #> Loading codec...\n",
      "[May 13, 02:45:08] #> Loading IVF...\n",
      "[May 13, 02:45:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2142.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American actor East side drug lord peaceful solutions business disputes site:imdb.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137,  3364,  2264,  2217,  4319,  2935,  9379,  7300,\n",
      "         2449, 11936,  2609,  1024, 10047, 18939,  1012,  4012,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 20  (0.0):  40%|████      | 20/50 [02:53<04:13,  8.46s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:11] #> Loading codec...\n",
      "[May 13, 02:45:11] #> Loading IVF...\n",
      "[May 13, 02:45:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"City north of birthplace of Toby Sawyer by 11 miles\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2103,  2167,  1997, 14508,  1997, 11291, 13975,\n",
      "         2011,  2340,  2661,  1000,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:15] #> Loading codec...\n",
      "[May 13, 02:45:15] #> Loading IVF...\n",
      "[May 13, 02:45:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1048.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . City 11 miles north of Manchester, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2103, 2340, 2661, 2167, 1997, 5087,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 21  (0.0):  42%|████▏     | 21/50 [03:01<03:56,  8.16s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:19] #> Loading codec...\n",
      "[May 13, 02:45:19] #> Loading IVF...\n",
      "[May 13, 02:45:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4152.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Tony Kaye birth date\" AND \"Deepa Mehta birth date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4116, 23686,  4182,  3058,  1000,  1998,  1000,\n",
      "         2784,  2050,  2033, 22893,  4182,  3058,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:23] #> Loading codec...\n",
      "[May 13, 02:45:23] #> Loading IVF...\n",
      "[May 13, 02:45:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1663.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Tony Kaye birthdate, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  4116, 23686,  4182, 13701,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 22  (0.0):  44%|████▍     | 22/50 [03:09<03:46,  8.07s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:27] #> Loading codec...\n",
      "[May 13, 02:45:27] #> Loading IVF...\n",
      "[May 13, 02:45:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1189.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Macy's Boise Town Square store replacement history\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 20914,  1005,  1055, 23193,  2237,  2675,  3573,\n",
      "         6110,  2381,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:31] #> Loading codec...\n",
      "[May 13, 02:45:31] #> Loading IVF...\n",
      "[May 13, 02:45:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1411.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Macy's Boise Town Square store replacement\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 20914,  1005,  1055, 23193,  2237,  2675,  3573,\n",
      "         6110,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 23  (0.0):  46%|████▌     | 23/50 [03:18<03:49,  8.50s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:36] #> Loading codec...\n",
      "[May 13, 02:45:36] #> Loading IVF...\n",
      "[May 13, 02:45:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1473.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Lizzette Reynolds November 2007 fired\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9056, 4371, 4674, 9579, 2281, 2289, 5045, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:41] #> Loading codec...\n",
      "[May 13, 02:45:41] #> Loading IVF...\n",
      "[May 13, 02:45:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4249.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Manager fired in November 2007 site:Wikipedia.org, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3208,  5045,  1999,  2281,  2289,  2609,  1024, 16948,\n",
      "         1012,  8917,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 24  (0.0):  48%|████▊     | 24/50 [03:27<03:42,  8.56s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:45] #> Loading codec...\n",
      "[May 13, 02:45:45] #> Loading IVF...\n",
      "[May 13, 02:45:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4514.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Boy Lightning Calculator\" nickname P.T. Barnum, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2879,  7407, 10250, 19879,  4263,  1000,  8367,\n",
      "         1052,  1012,  1056,  1012,  8659,  2819,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:50] #> Loading codec...\n",
      "[May 13, 02:45:50] #> Loading IVF...\n",
      "[May 13, 02:45:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4639.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Boy Lightning Calculator\" P.T. Barnum, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2879,  7407, 10250, 19879,  4263,  1000,  1052,\n",
      "         1012,  1056,  1012,  8659,  2819,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 25  (0.0):  50%|█████     | 25/50 [03:35<03:34,  8.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:53] #> Loading codec...\n",
      "[May 13, 02:45:53] #> Loading IVF...\n",
      "[May 13, 02:45:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3916.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Duration of Battle of the Ch'ongch'on River vs. Duration of Meuse-Argonne Offensive, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9367,  1997,  2645,  1997,  1996, 10381,  1005,  2006,\n",
      "        18195,  2232,  1005,  2006,  2314,  5443,  1012,  9367,  1997,  2033,\n",
      "         8557,  1011, 12098,  7446,  2638,  5805,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:45:59] #> Loading codec...\n",
      "[May 13, 02:45:59] #> Loading IVF...\n",
      "[May 13, 02:45:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1534.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:45:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 183.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Duration of the Meuse-Argonne Offensive vs. Battle of the Ch'ongch'on River, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9367,  1997,  1996,  2033,  8557,  1011, 12098,  7446,\n",
      "         2638,  5805,  5443,  1012,  2645,  1997,  1996, 10381,  1005,  2006,\n",
      "        18195,  2232,  1005,  2006,  2314,   102,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 26  (0.0):  52%|█████▏    | 26/50 [03:44<03:28,  8.69s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:02] #> Loading codec...\n",
      "[May 13, 02:46:02] #> Loading IVF...\n",
      "[May 13, 02:46:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4554.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"cricketer active 1974-1993 Australian cricket team England tour 1981 performance\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9490, 3161, 3326, 1011, 2857, 2827, 4533, 2136, 2563,\n",
      "        2778, 3261, 2836, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:07] #> Loading codec...\n",
      "[May 13, 02:46:07] #> Loading IVF...\n",
      "[May 13, 02:46:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1478.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Australian cricket team tour England 1981 player performance site:cricketarchive.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2827, 4533, 2136, 2778, 2563, 3261, 2447, 2836, 2609, 1024,\n",
      "        4533, 2906, 5428, 3726, 1012, 4012,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 27  (0.0):  54%|█████▍    | 27/50 [03:53<03:20,  8.72s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:11] #> Loading codec...\n",
      "[May 13, 02:46:11] #> Loading IVF...\n",
      "[May 13, 02:46:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1509.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Monte Kiffin current job\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10125, 11382, 15379,  2783,  3105,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:15] #> Loading codec...\n",
      "[May 13, 02:46:15] #> Loading IVF...\n",
      "[May 13, 02:46:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1110.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Head coach of the 1982 NC State Wolfpack football team, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2132,  2873,  1997,  1996,  3196, 13316,  2110,  4702,\n",
      "        23947,  2374,  2136,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 28  (0.0):  56%|█████▌    | 28/50 [04:02<03:10,  8.64s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:20] #> Loading codec...\n",
      "[May 13, 02:46:20] #> Loading IVF...\n",
      "[May 13, 02:46:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3718.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Ewan McGregor \"Come What May\" singer, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1041,  7447, 23023,  1000,  2272,  2054,  2089,  1000,\n",
      "         3220,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:24] #> Loading codec...\n",
      "[May 13, 02:46:25] #> Loading IVF...\n",
      "[May 13, 02:46:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1456.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Ewan McGregor \"Come What May\" singer., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1041,  7447, 23023,  1000,  2272,  2054,  2089,  1000,\n",
      "         3220,  1012,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 29  (0.0):  58%|█████▊    | 29/50 [04:10<03:01,  8.62s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:28] #> Loading codec...\n",
      "[May 13, 02:46:28] #> Loading IVF...\n",
      "[May 13, 02:46:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ivan Bella space missions\" AND \"Frank De Winne space missions\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  7332, 12101,  2686,  6416,  1000,  1998,  1000,\n",
      "         3581,  2139,  2663,  2638,  2686,  6416,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:33] #> Loading codec...\n",
      "[May 13, 02:46:33] #> Loading IVF...\n",
      "[May 13, 02:46:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1266.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ivan Bella Frank De Winne space travel destinations\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  7332, 12101,  3581,  2139,  2663,  2638,  2686,\n",
      "         3604, 14345,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 30  (0.0):  60%|██████    | 30/50 [04:19<02:53,  8.67s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:37] #> Loading codec...\n",
      "[May 13, 02:46:37] #> Loading IVF...\n",
      "[May 13, 02:46:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1139.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Anton Chekhov disillusioned schoolmaster play\" + \"British playwright adaptation\" + \"original work intended audience\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9865, 18178, 25495,  4487, 27572, 24117,  2098,\n",
      "         2082,  8706,  2377,  1000,  1009,  1000,  2329, 11170,  6789,  1000,\n",
      "         1009,  1000,  2434,  2147,  3832,  4378,  1000,   102,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:41] #> Loading codec...\n",
      "[May 13, 02:46:41] #> Loading IVF...\n",
      "[May 13, 02:46:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Anton Chekhov disillusioned schoolmaster play\" \"British playwright\" \"specifically written for\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9865, 18178, 25495,  4487, 27572, 24117,  2098,\n",
      "         2082,  8706,  2377,  1000,  1000,  2329, 11170,  1000,  1000,  4919,\n",
      "         2517,  2005,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 31  (0.0):  62%|██████▏   | 31/50 [04:28<02:48,  8.85s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:46] #> Loading codec...\n",
      "[May 13, 02:46:46] #> Loading IVF...\n",
      "[May 13, 02:46:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3587.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Mainland US definition\" + \"Roswell International Air Center location\" + \"Pago Pago International Airport location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  8240,  2149,  6210,  1000,  1009,  1000, 20996,\n",
      "        19228,  2248,  2250,  2415,  3295,  1000,  1009,  1000,  6643,  3995,\n",
      "         6643,  3995,  2248,  3199,  3295,  1000,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:51] #> Loading codec...\n",
      "[May 13, 02:46:51] #> Loading IVF...\n",
      "[May 13, 02:46:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1576.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are Roswell International Air Center and Pago Pago International Airport both located in the mainland US?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024, 20996, 19228,  2248,  2250,  2415,  1998,  6643,\n",
      "         3995,  6643,  3995,  2248,  3199,  2119,  2284,  1999,  1996,  8240,\n",
      "         2149,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 32  (0.0):  64%|██████▍   | 32/50 [04:38<02:44,  9.14s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:46:56] #> Loading codec...\n",
      "[May 13, 02:46:56] #> Loading IVF...\n",
      "[May 13, 02:46:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1526.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:46:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Untold: The Greatest Sports Stories Never Told\" host sportscaster name, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 19662,  6392,  1024,  1996,  4602,  2998,  3441,\n",
      "         2196,  2409,  1000,  3677,  2998, 25490,  2171,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:01] #> Loading codec...\n",
      "[May 13, 02:47:01] #> Loading IVF...\n",
      "[May 13, 02:47:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1673.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . List of hosts or presenters of \"Untold: The Greatest Sports Stories Never Told\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2862,  1997,  6184,  2030, 25588,  1997,  1000, 19662,\n",
      "         6392,  1024,  1996,  4602,  2998,  3441,  2196,  2409,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 33  (0.0):  66%|██████▌   | 33/50 [04:47<02:31,  8.92s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:05] #> Loading codec...\n",
      "[May 13, 02:47:05] #> Loading IVF...\n",
      "[May 13, 02:47:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1279.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Walt Disney documentary film\" OR \"Sacro GRA documentary film\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10598,  6373,  4516,  2143,  1000,  2030,  1000,\n",
      "        17266,  3217, 24665,  2050,  4516,  2143,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:09] #> Loading codec...\n",
      "[May 13, 02:47:09] #> Loading IVF...\n",
      "[May 13, 02:47:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4593.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Genre of Walt Disney films vs. Genre of Sacro GRA documentary, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6907,  1997, 10598,  6373,  3152,  5443,  1012,  6907,\n",
      "         1997, 17266,  3217, 24665,  2050,  4516,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 34  (0.0):  68%|██████▊   | 34/50 [04:56<02:23,  8.99s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:14] #> Loading codec...\n",
      "[May 13, 02:47:14] #> Loading IVF...\n",
      "[May 13, 02:47:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4236.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"governing organization of Gaza Strip\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  8677,  3029,  1997, 14474,  6167,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:18] #> Loading codec...\n",
      "[May 13, 02:47:18] #> Loading IVF...\n",
      "[May 13, 02:47:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4675.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Palestinian Islamic organization governing territory captured by Israel in 1967 Six-Day War, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 9302, 5499, 3029, 8677, 3700, 4110, 2011, 3956, 1999, 3476,\n",
      "        2416, 1011, 2154, 2162,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 35  (0.0):  70%|███████   | 35/50 [05:04<02:13,  8.87s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:22] #> Loading codec...\n",
      "[May 13, 02:47:22] #> Loading IVF...\n",
      "[May 13, 02:47:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Taylor Swift 2015 MTV Video Music Awards pre-show song album\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4202, 9170, 2325, 8692, 2678, 2189, 2982, 3653, 1011,\n",
      "        2265, 2299, 2201, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:27] #> Loading codec...\n",
      "[May 13, 02:47:27] #> Loading IVF...\n",
      "[May 13, 02:47:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3015.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Taylor Swift 2015 album song premiered at MTV Video Music Awards, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 4202, 9170, 2325, 2201, 2299, 5885, 2012, 8692, 2678, 2189,\n",
      "        2982,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 36  (0.0):  72%|███████▏  | 36/50 [05:14<02:09,  9.23s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:32] #> Loading codec...\n",
      "[May 13, 02:47:32] #> Loading IVF...\n",
      "[May 13, 02:47:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1516.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Apera genus classification\" OR \"Gunnera manicata genus classification\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 23957,  2527,  3562,  5579,  1000,  2030,  1000,\n",
      "        14850,  2050, 23624, 11266,  2050,  3562,  5579,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:39] #> Loading codec...\n",
      "[May 13, 02:47:39] #> Loading IVF...\n",
      "[May 13, 02:47:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1306.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"scientific classification of Apera\" OR \"scientific classification of Gunnera manicata\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4045,  5579,  1997, 23957,  2527,  1000,  2030,\n",
      "         1000,  4045,  5579,  1997, 14850,  2050, 23624, 11266,  2050,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 37  (0.0):  74%|███████▍  | 37/50 [05:24<02:03,  9.48s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:43] #> Loading codec...\n",
      "[May 13, 02:47:43] #> Loading IVF...\n",
      "[May 13, 02:47:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4072.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"music genres of The Drums\" OR \"music genres of Pussy Galore\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2189, 11541,  1997,  1996,  3846,  1000,  2030,\n",
      "         1000,  2189, 11541,  1997, 22418, 14891,  5686,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:47] #> Loading codec...\n",
      "[May 13, 02:47:47] #> Loading IVF...\n",
      "[May 13, 02:47:47] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1149.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:47] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Discography and music style comparison between The Drums and Pussy Galore., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 12532, 12565,  1998,  2189,  2806,  7831,  2090,  1996,\n",
      "         3846,  1998, 22418, 14891,  5686,  1012,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 38  (0.0):  76%|███████▌  | 38/50 [05:32<01:48,  9.04s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:50] #> Loading codec...\n",
      "[May 13, 02:47:50] #> Loading IVF...\n",
      "[May 13, 02:47:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1359.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"University of Exeter post-nominal abbreviation\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2118,  1997, 12869,  2695,  1011, 15087, 22498,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:55] #> Loading codec...\n",
      "[May 13, 02:47:55] #> Loading IVF...\n",
      "[May 13, 02:47:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4128.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the post-nominal abbreviation for the university where the Banded Mongoose Research Project is based?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2695,  1011, 15087, 22498,  2005,\n",
      "         1996,  2118,  2073,  1996, 25264, 12256,  3995,  9232,  2470,  2622,\n",
      "         2003,  2241,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 39  (0.0):  78%|███████▊  | 39/50 [05:40<01:35,  8.70s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:47:58] #> Loading codec...\n",
      "[May 13, 02:47:58] #> Loading IVF...\n",
      "[May 13, 02:47:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3844.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:47:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Benjamin Christensen director\" OR \"Len Wiseman director\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  6425, 24189,  2472,  1000,  2030,  1000, 18798,\n",
      "         7968,  2386,  2472,  1000,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:03] #> Loading codec...\n",
      "[May 13, 02:48:03] #> Loading IVF...\n",
      "[May 13, 02:48:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1700.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Chelsea Football Club directors list\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9295, 2374, 2252, 5501, 2862, 1000,  102,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 40  (0.0):  80%|████████  | 40/50 [05:49<01:26,  8.64s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:07] #> Loading codec...\n",
      "[May 13, 02:48:07] #> Loading IVF...\n",
      "[May 13, 02:48:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1647.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American animator who worked with Steven Cuitlahuac Melendez and Disney, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137, 25132,  2040,  2499,  2007,  7112, 12731,  4183,\n",
      "        14431,  6692,  2278, 11463, 28787,  1998,  6373,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:11] #> Loading codec...\n",
      "[May 13, 02:48:11] #> Loading IVF...\n",
      "[May 13, 02:48:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4733.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Did Steven Cuitlahuac Melendez work on the film John Carter?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2106,  7112, 12731,  4183, 14431,  6692,  2278, 11463,\n",
      "        28787,  2147,  2006,  1996,  2143,  2198,  5708,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 41  (0.0):  82%|████████▏ | 41/50 [05:57<01:15,  8.42s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:15] #> Loading codec...\n",
      "[May 13, 02:48:15] #> Loading IVF...\n",
      "[May 13, 02:48:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1284.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Northern Rivers District rivers list Shark Creek site:gov.au, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2642,  5485,  2212,  5485,  2862, 11420,  3636,  2609,\n",
      "         1024, 18079,  1012,  8740,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:18] #> Loading codec...\n",
      "[May 13, 02:48:18] #> Loading IVF...\n",
      "[May 13, 02:48:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1757.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Shark Creek northern rivers district river\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 11420,  3636,  2642,  5485,  2212,  2314,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 42  (0.0):  84%|████████▍ | 42/50 [06:04<01:04,  8.12s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:22] #> Loading codec...\n",
      "[May 13, 02:48:22] #> Loading IVF...\n",
      "[May 13, 02:48:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4476.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Finding Dory\" 2016 animated film producer, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4531, 2079, 2854, 1000, 2355, 6579, 2143, 3135,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:27] #> Loading codec...\n",
      "[May 13, 02:48:27] #> Loading IVF...\n",
      "[May 13, 02:48:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3560.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Finding Dory 2016 film producer\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4531, 2079, 2854, 2355, 2143, 3135, 1000,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 43  (0.0):  86%|████████▌ | 43/50 [06:12<00:57,  8.16s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:30] #> Loading codec...\n",
      "[May 13, 02:48:30] #> Loading IVF...\n",
      "[May 13, 02:48:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2281.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ferrari new owner 2000\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 13632,  2047,  3954,  2456,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:35] #> Loading codec...\n",
      "[May 13, 02:48:35] #> Loading IVF...\n",
      "[May 13, 02:48:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1558.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who purchased the Benetton Formula One team from Renault in 2000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  4156,  1996,  3841, 20082,  2078,  5675,  2028,\n",
      "         2136,  2013, 14605,  1999,  2456,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 44  (0.0):  88%|████████▊ | 44/50 [06:21<00:49,  8.23s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:38] #> Loading codec...\n",
      "[May 13, 02:48:38] #> Loading IVF...\n",
      "[May 13, 02:48:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1375.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fredrick Law Olmsted projects in Trenton, New Jersey\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  5965, 11285,  2375, 19330,  5244,  3064,  3934,\n",
      "         1999, 17148,  1010,  2047,  3933,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:43] #> Loading codec...\n",
      "[May 13, 02:48:43] #> Loading IVF...\n",
      "[May 13, 02:48:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fredrick Law Olmsted projects in Trenton, New Jersey\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  5965, 11285,  2375, 19330,  5244,  3064,  3934,\n",
      "         1999, 17148,  1010,  2047,  3933,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 45  (0.0):  90%|█████████ | 45/50 [06:29<00:40,  8.14s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:46] #> Loading codec...\n",
      "[May 13, 02:48:46] #> Loading IVF...\n",
      "[May 13, 02:48:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4013.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Cast list of Young Toscanini movie, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3459,  2862,  1997,  2402,  2000, 29378,  5498,  3185,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:51] #> Loading codec...\n",
      "[May 13, 02:48:51] #> Loading IVF...\n",
      "[May 13, 02:48:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3927.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Young Toscanini\" former senator political party Gordon Warnecke, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2402,  2000, 29378,  5498,  1000,  2280,  5205,\n",
      "         2576,  2283,  5146, 11582, 11012,  2063,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 46  (0.0):  92%|█████████▏| 46/50 [06:37<00:32,  8.08s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:54] #> Loading codec...\n",
      "[May 13, 02:48:54] #> Loading IVF...\n",
      "[May 13, 02:48:54] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3792.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:54] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nazi organization publisher of German propaganda magazine André Zucca worked for, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6394,  3029,  6674,  1997,  2446, 10398,  2932,  7213,\n",
      "        16950, 16665,  2499,  2005,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:48:59] #> Loading codec...\n",
      "[May 13, 02:48:59] #> Loading IVF...\n",
      "[May 13, 02:48:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4271.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:48:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nazi propaganda magazine André Zucca worked for during World War II, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6394, 10398,  2932,  7213, 16950, 16665,  2499,  2005,\n",
      "         2076,  2088,  2162,  2462,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 47  (0.0):  94%|█████████▍| 47/50 [06:45<00:24,  8.06s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:03] #> Loading codec...\n",
      "[May 13, 02:49:03] #> Loading IVF...\n",
      "[May 13, 02:49:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1343.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Bill Ponsford profession\" \"Bill Woodfull profession\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3021, 13433,  3619,  3877,  9518,  1000,  1000,\n",
      "         3021,  3536,  3993,  2140,  9518,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:07] #> Loading codec...\n",
      "[May 13, 02:49:07] #> Loading IVF...\n",
      "[May 13, 02:49:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1558.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What sport did Bill Ponsford and Bill Woodfull play?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4368,  2106,  3021, 13433,  3619,  3877,  1998,\n",
      "         3021,  3536,  3993,  2140,  2377,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 48  (0.0):  96%|█████████▌| 48/50 [06:53<00:16,  8.08s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:11] #> Loading codec...\n",
      "[May 13, 02:49:11] #> Loading IVF...\n",
      "[May 13, 02:49:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4052.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Films Suzana S. Drobnjaković Ponti acted in based on books, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3152, 10514, 13471,  2050,  1055,  1012,  2852, 16429,\n",
      "         2078, 18317,  9142, 21179,  2072,  6051,  1999,  2241,  2006,  2808,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:15] #> Loading codec...\n",
      "[May 13, 02:49:15] #> Loading IVF...\n",
      "[May 13, 02:49:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4871.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Suzana S. Drobnjaković Ponti filmography based on books adaptations, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10514, 13471,  2050,  1055,  1012,  2852, 16429,  2078,\n",
      "        18317,  9142, 21179,  2072,  2143,  9888,  2241,  2006,  2808, 17241,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 49  (0.0):  98%|█████████▊| 49/50 [07:02<00:08,  8.33s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:21] #> Loading codec...\n",
      "[May 13, 02:49:21] #> Loading IVF...\n",
      "[May 13, 02:49:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Location of Election Law Journal headquarters\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 3295, 1997, 2602, 2375, 3485, 4075, 1000,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:24] #> Loading codec...\n",
      "[May 13, 02:49:24] #> Loading IVF...\n",
      "[May 13, 02:49:24] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3554.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Election Law Journal founding city\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2602, 2375, 3485, 4889, 2103, 1000,  102,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 50  (0.0): 100%|██████████| 50/50 [07:10<00:00,  8.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fe8e9 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fe8e9 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fe8e9_row0_col0, #T_fe8e9_row0_col1, #T_fe8e9_row0_col2, #T_fe8e9_row0_col3, #T_fe8e9_row0_col4, #T_fe8e9_row0_col5, #T_fe8e9_row1_col0, #T_fe8e9_row1_col1, #T_fe8e9_row1_col2, #T_fe8e9_row1_col3, #T_fe8e9_row1_col4, #T_fe8e9_row1_col5, #T_fe8e9_row2_col0, #T_fe8e9_row2_col1, #T_fe8e9_row2_col2, #T_fe8e9_row2_col3, #T_fe8e9_row2_col4, #T_fe8e9_row2_col5, #T_fe8e9_row3_col0, #T_fe8e9_row3_col1, #T_fe8e9_row3_col2, #T_fe8e9_row3_col3, #T_fe8e9_row3_col4, #T_fe8e9_row3_col5, #T_fe8e9_row4_col0, #T_fe8e9_row4_col1, #T_fe8e9_row4_col2, #T_fe8e9_row4_col3, #T_fe8e9_row4_col4, #T_fe8e9_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fe8e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fe8e9_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_fe8e9_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_fe8e9_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_fe8e9_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_fe8e9_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_fe8e9_level0_col5\" class=\"col_heading level0 col5\" >gold_passages_retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fe8e9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fe8e9_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_fe8e9_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_fe8e9_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_fe8e9_row0_col3\" class=\"data row0 col3\" >[\"Shenzhen Peng City (2019–present)\\nOn 20 February 2019, it was announced that CFG as well as UBTECH and China Sports Capital had acquired Sichuan Jiuniu F.C.\\n...</td>\n",
       "      <td id=\"T_fe8e9_row0_col4\" class=\"data row0 col4\" >No, Cangzhou is in Hebei province, while Qionghai is in Hainan province.</td>\n",
       "      <td id=\"T_fe8e9_row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe8e9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fe8e9_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_fe8e9_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_fe8e9_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_fe8e9_row1_col3\" class=\"data row1 col3\" >['and Goal of the Season. The Young Player of the Season award is given to the most outstanding U-23 player starting from the 2019–20 season.\\nThe...</td>\n",
       "      <td id=\"T_fe8e9_row1_col4\" class=\"data row1 col4\" >The National Hockey League (NHL) conducted the draft.</td>\n",
       "      <td id=\"T_fe8e9_row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe8e9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fe8e9_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_fe8e9_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_fe8e9_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_fe8e9_row2_col3\" class=\"data row2 col3\" >['Fourteen Liverpool fans received convictions for involuntary manslaughter.\\nFagan had announced his retirement just before the disaster and Kenny Dalglish was appointed as player-manager. During his...</td>\n",
       "      <td id=\"T_fe8e9_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_fe8e9_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe8e9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fe8e9_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_fe8e9_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_fe8e9_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_fe8e9_row3_col3\" class=\"data row3 col3\" >[\"A new training ground was constructed at the site for £45 million, which opened in 2012. The 77-acre site has 15 grass pitches and one-and-a-half...</td>\n",
       "      <td id=\"T_fe8e9_row3_col4\" class=\"data row3 col4\" >The River Tyne.</td>\n",
       "      <td id=\"T_fe8e9_row3_col5\" class=\"data row3 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe8e9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fe8e9_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_fe8e9_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_fe8e9_row4_col2\" class=\"data row4 col2\" >{'Ealhswith', 'Æthelweard (son of Alfred)'}</td>\n",
       "      <td id=\"T_fe8e9_row4_col3\" class=\"data row4 col3\" >[\"Promoted to the board a few days after the Munich air disaster, Louis Edwards, a friend of Matt Busby, began acquiring shares in the club;...</td>\n",
       "      <td id=\"T_fe8e9_row4_col4\" class=\"data row4 col4\" >Alfred the Great</td>\n",
       "      <td id=\"T_fe8e9_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f00cc548970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:28] #> Loading codec...\n",
      "[May 13, 02:49:28] #> Loading IVF...\n",
      "[May 13, 02:49:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3539.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Cangzhou location province China\" AND \"Qionghai location province China\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2064,  2290,  9791,  3295,  2874,  2859,  1000,\n",
      "         1998,  1000, 18816,  5063, 10932,  3295,  2874,  2859,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:31] #> Loading codec...\n",
      "[May 13, 02:49:31] #> Loading IVF...\n",
      "[May 13, 02:49:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4519.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Cangzhou and Qionghai in China, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997,  2064,  2290,  9791,  1998, 18816,  5063,\n",
      "        10932,  1999,  2859,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0):   2%|▏         | 1/50 [00:06<05:28,  6.70s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:35] #> Loading codec...\n",
      "[May 13, 02:49:35] #> Loading IVF...\n",
      "[May 13, 02:49:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1439.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"2017 NHL Expansion Draft conductors\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2418,  7097,  4935,  4433, 23396,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:38] #> Loading codec...\n",
      "[May 13, 02:49:38] #> Loading IVF...\n",
      "[May 13, 02:49:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1384.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who conducted the NHL draft for the 2017-18 season?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 4146, 1996, 7097, 4433, 2005, 1996, 2418, 1011, 2324,\n",
      "        2161, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   4%|▍         | 2/50 [00:13<05:20,  6.68s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:42] #> Loading codec...\n",
      "[May 13, 02:49:42] #> Loading IVF...\n",
      "[May 13, 02:49:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1444.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 174.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Canadian retired professional ice hockey player general manager Tampa Bay Lightning\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 3010, 3394, 2658, 3256, 3873, 2447, 2236, 3208, 9925,\n",
      "        3016, 7407, 1000,  102,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:45] #> Loading codec...\n",
      "[May 13, 02:49:45] #> Loading IVF...\n",
      "[May 13, 02:49:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4271.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who is the Canadian retired professional ice hockey player and current general manager of the Tampa Bay Lightning of the National Hockey League (NHL) following the retirement of Steve Yzerman?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([40]), tensor([ 101,    1, 2040, 2003, 1996, 3010, 3394, 2658, 3256, 3873, 2447, 1998,\n",
      "        2783, 2236, 3208, 1997, 1996, 9925, 3016, 7407, 1997, 1996, 2120, 3873,\n",
      "        2223, 1006, 7097, 1007, 2206, 1996, 5075, 1997, 3889, 1061, 6290, 2386,\n",
      "        1029,  102,  103,  103])\n",
      "#> Output Mask: torch.Size([40]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):   6%|▌         | 3/50 [00:20<05:30,  7.03s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:49] #> Loading codec...\n",
      "[May 13, 02:49:49] #> Loading IVF...\n",
      "[May 13, 02:49:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1356.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"town near Crichton Collegiate Church\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2237,  2379, 13675,  7033,  2669,  9234,  2277,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:51] #> Loading codec...\n",
      "[May 13, 02:49:52] #> Loading IVF...\n",
      "[May 13, 02:49:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4036.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Rivers near Crichton Collegiate Church Dumfries Scotland, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  5485,  2379, 13675,  7033,  2669,  9234,  2277,  4241,\n",
      "         2213, 19699,  3111,  3885,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 4  (0.0):   8%|▊         | 4/50 [00:27<05:18,  6.93s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:56] #> Loading codec...\n",
      "[May 13, 02:49:56] #> Loading IVF...\n",
      "[May 13, 02:49:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1680.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Father of Æthelweard son of Ealhswith\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2269,  1997,  1097, 10760,  2140, 16689,  2094,\n",
      "         2365,  1997, 19413,  2140,  7898, 24415,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:49:59] #> Loading codec...\n",
      "[May 13, 02:49:59] #> Loading IVF...\n",
      "[May 13, 02:49:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 964.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:49:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who was the father of Æthelweard, son of Ealhswith, in the 10th Century A.D.?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  1996,  2269,  1997,  1097, 10760,  2140,\n",
      "        16689,  2094,  1010,  2365,  1997, 19413,  2140,  7898, 24415,  1010,\n",
      "         1999,  1996,  6049,  2301,  1037,  1012,  1040,  1012,  1029,   102,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 5  (0.0):  10%|█         | 5/50 [00:34<05:10,  6.90s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:03] #> Loading codec...\n",
      "[May 13, 02:50:03] #> Loading IVF...\n",
      "[May 13, 02:50:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4568.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Newark Airport Exchange operator\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 12948,  3199,  3863,  6872,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:05] #> Loading codec...\n",
      "[May 13, 02:50:05] #> Loading IVF...\n",
      "[May 13, 02:50:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4306.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who operates Newark Airport?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  5748, 12948,  3199,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 6  (0.0):  12%|█▏        | 6/50 [00:40<04:56,  6.75s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:10] #> Loading codec...\n",
      "[May 13, 02:50:10] #> Loading IVF...\n",
      "[May 13, 02:50:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1289.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Peruvian footballer goal domestic double win event location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 15432,  4362,  3125,  4968,  3313,  2663,  2724,\n",
      "         3295,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:13] #> Loading codec...\n",
      "[May 13, 02:50:13] #> Loading IVF...\n",
      "[May 13, 02:50:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3026.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Peruvian footballer domestic double win location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 15432,  4362,  4968,  3313,  2663,  3295,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 7  (0.0):  14%|█▍        | 7/50 [00:48<05:02,  7.04s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:17] #> Loading codec...\n",
      "[May 13, 02:50:17] #> Loading IVF...\n",
      "[May 13, 02:50:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4471.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Chico Municipal Airport location\" AND \"William R. Fairchild International Airport location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 22136,  4546,  3199,  3295,  1000,  1998,  1000,\n",
      "         2520,  1054,  1012, 24258,  2248,  3199,  3295,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:19] #> Loading codec...\n",
      "[May 13, 02:50:19] #> Loading IVF...\n",
      "[May 13, 02:50:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1170.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Chico Municipal Airport and William R. Fairchild International Airport, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997, 22136,  4546,  3199,  1998,  2520,  1054,\n",
      "         1012, 24258,  2248,  3199,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 8  (0.0):  16%|█▌        | 8/50 [00:54<04:43,  6.76s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:23] #> Loading codec...\n",
      "[May 13, 02:50:23] #> Loading IVF...\n",
      "[May 13, 02:50:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4096.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fort Pownall location Maine county\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3481, 23776, 22270,  3295,  7081,  2221,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:25] #> Loading codec...\n",
      "[May 13, 02:50:25] #> Loading IVF...\n",
      "[May 13, 02:50:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Location of Fort Pownall, Maine county, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3295,  1997,  3481, 23776, 22270,  1010,  7081,  2221,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 9  (0.0):  18%|█▊        | 9/50 [01:01<04:39,  6.82s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:30] #> Loading codec...\n",
      "[May 13, 02:50:30] #> Loading IVF...\n",
      "[May 13, 02:50:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1243.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Gene band reunion date\" OR \"The Afghan Whigs band reunion date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4962,  2316, 10301,  3058,  1000,  2030,  1000,\n",
      "         1996, 12632, 21632,  2015,  2316, 10301,  3058,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:32] #> Loading codec...\n",
      "[May 13, 02:50:32] #> Loading IVF...\n",
      "[May 13, 02:50:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Gene band reunion date\" OR \"The Afghan Whigs band reunion date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4962,  2316, 10301,  3058,  1000,  2030,  1000,\n",
      "         1996, 12632, 21632,  2015,  2316, 10301,  3058,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 10  (0.0):  20%|██        | 10/50 [01:08<04:35,  6.90s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:37] #> Loading codec...\n",
      "[May 13, 02:50:37] #> Loading IVF...\n",
      "[May 13, 02:50:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3563.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Monte Vesuvio eruption date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10125,  2310,  6342, 25500, 17259,  3058,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:39] #> Loading codec...\n",
      "[May 13, 02:50:39] #> Loading IVF...\n",
      "[May 13, 02:50:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4860.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Year of eruption of Mount Vesuvius in Italy., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2095,  1997, 17259,  1997,  4057,  2310,  6342, 26055,\n",
      "         1999,  3304,  1012,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 11  (0.0):  22%|██▏       | 11/50 [01:14<04:21,  6.70s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:43] #> Loading codec...\n",
      "[May 13, 02:50:43] #> Loading IVF...\n",
      "[May 13, 02:50:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Establishment date of 72nd field brigade\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 5069, 3058, 1997, 5824, 4859, 2492, 4250, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:46] #> Loading codec...\n",
      "[May 13, 02:50:46] #> Loading IVF...\n",
      "[May 13, 02:50:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3483.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Establishment date of 72nd field brigade\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 5069, 3058, 1997, 5824, 4859, 2492, 4250, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 12  (0.0):  24%|██▍       | 12/50 [01:20<04:06,  6.50s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:49] #> Loading codec...\n",
      "[May 13, 02:50:49] #> Loading IVF...\n",
      "[May 13, 02:50:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1431.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Stanislaw Kiszka payment Royal Treasury\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9761,  2483, 14919, 11382, 17112,  2912,  7909,\n",
      "         2548,  9837,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:52] #> Loading codec...\n",
      "[May 13, 02:50:52] #> Loading IVF...\n",
      "[May 13, 02:50:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3695.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Stanislaw Kiszka payment Royal Treasury\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9761,  2483, 14919, 11382, 17112,  2912,  7909,\n",
      "         2548,  9837,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 13  (0.0):  26%|██▌       | 13/50 [01:27<04:02,  6.55s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:56] #> Loading codec...\n",
      "[May 13, 02:50:56] #> Loading IVF...\n",
      "[May 13, 02:50:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1971.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Del Lord birthdate\" OR \"Wang Xiaoshuai birthdate\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3972,  2935,  4182, 13701,  1000,  2030,  1000,\n",
      "         7418, 19523, 14235,  4886,  4182, 13701,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:50:59] #> Loading codec...\n",
      "[May 13, 02:50:59] #> Loading IVF...\n",
      "[May 13, 02:50:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1935.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:50:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Del Lord birth date\" AND \"Wang Xiaoshuai birth date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3972,  2935,  4182,  3058,  1000,  1998,  1000,\n",
      "         7418, 19523, 14235,  4886,  4182,  3058,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 14  (0.0):  28%|██▊       | 14/50 [01:34<03:56,  6.58s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:02] #> Loading codec...\n",
      "[May 13, 02:51:02] #> Loading IVF...\n",
      "[May 13, 02:51:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3432.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Former Conservative MP perjury 1999 site:Lord North Street\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2280, 4603, 6131, 2566, 9103, 2854, 2639, 2609, 1024,\n",
      "        2935, 2167, 2395, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:05] #> Loading codec...\n",
      "[May 13, 02:51:05] #> Loading IVF...\n",
      "[May 13, 02:51:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2253.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Residents of Lord North Street London, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 3901, 1997, 2935, 2167, 2395, 2414,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 15  (0.0):  30%|███       | 15/50 [01:41<03:51,  6.61s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:09] #> Loading codec...\n",
      "[May 13, 02:51:09] #> Loading IVF...\n",
      "[May 13, 02:51:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3876.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Name of Marche region Italy, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2171,  1997, 28791,  2555,  3304,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:12] #> Loading codec...\n",
      "[May 13, 02:51:12] #> Loading IVF...\n",
      "[May 13, 02:51:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3597.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What region of Italy includes the March of Ancona, Camerino, and Fermo?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2555,  1997,  3304,  2950,  1996,  2233,  1997,\n",
      "         2019, 24366,  1010,  2234, 17815,  1010,  1998, 10768, 10867,  2080,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 16  (0.0):  32%|███▏      | 16/50 [01:47<03:46,  6.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:16] #> Loading codec...\n",
      "[May 13, 02:51:16] #> Loading IVF...\n",
      "[May 13, 02:51:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3890.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Population of [city name]\"., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2313, 1997, 1031, 2103, 2171, 1033, 1000, 1012,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:19] #> Loading codec...\n",
      "[May 13, 02:51:19] #> Loading IVF...\n",
      "[May 13, 02:51:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 937.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Population of Manchester in [year of William Hughes Miller's birth], \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2313, 1997, 5087, 1999, 1031, 2095, 1997, 2520, 8099, 4679,\n",
      "        1005, 1055, 4182, 1033,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 17  (0.0):  34%|███▍      | 17/50 [01:54<03:39,  6.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:23] #> Loading codec...\n",
      "[May 13, 02:51:23] #> Loading IVF...\n",
      "[May 13, 02:51:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3415.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"New York University school activities for art students\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2047, 2259, 2118, 2082, 3450, 2005, 2396, 2493, 1000,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:25] #> Loading codec...\n",
      "[May 13, 02:51:25] #> Loading IVF...\n",
      "[May 13, 02:51:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3269.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"New York University Meleko Mokgosi curriculum courses activities\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2047,  2259,  2118, 11463,  5937,  2080,  9587,\n",
      "         2243, 12333,  2072,  8882,  5352,  3450,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 18  (0.0):  36%|███▌      | 18/50 [02:01<03:37,  6.79s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:30] #> Loading codec...\n",
      "[May 13, 02:51:30] #> Loading IVF...\n",
      "[May 13, 02:51:30] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1337.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:30] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Robert Irvine nationality\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2728, 16272, 10662,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:32] #> Loading codec...\n",
      "[May 13, 02:51:32] #> Loading IVF...\n",
      "[May 13, 02:51:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3084.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nationality of Robert Irvine chef and restaurateur, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10662,  1997,  2728, 16272, 10026,  1998,  2717, 21159,\n",
      "         3686,  3126,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 19  (0.0):  38%|███▊      | 19/50 [02:07<03:27,  6.68s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:36] #> Loading codec...\n",
      "[May 13, 02:51:36] #> Loading IVF...\n",
      "[May 13, 02:51:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4056.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American actor East side drug lord peaceful solutions site:imdb.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137,  3364,  2264,  2217,  4319,  2935,  9379,  7300,\n",
      "         2609,  1024, 10047, 18939,  1012,  4012,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:39] #> Loading codec...\n",
      "[May 13, 02:51:39] #> Loading IVF...\n",
      "[May 13, 02:51:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1172.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American actor East side drug lord peaceful solutions business disputes site:imdb.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137,  3364,  2264,  2217,  4319,  2935,  9379,  7300,\n",
      "         2449, 11936,  2609,  1024, 10047, 18939,  1012,  4012,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 20  (0.0):  40%|████      | 20/50 [02:15<03:24,  6.81s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:43] #> Loading codec...\n",
      "[May 13, 02:51:43] #> Loading IVF...\n",
      "[May 13, 02:51:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1476.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"City north of birthplace of Toby Sawyer by 11 miles\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2103,  2167,  1997, 14508,  1997, 11291, 13975,\n",
      "         2011,  2340,  2661,  1000,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:46] #> Loading codec...\n",
      "[May 13, 02:51:46] #> Loading IVF...\n",
      "[May 13, 02:51:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1182.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . City 11 miles north of Manchester, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2103, 2340, 2661, 2167, 1997, 5087,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 21  (0.0):  42%|████▏     | 21/50 [02:21<03:16,  6.77s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:50] #> Loading codec...\n",
      "[May 13, 02:51:50] #> Loading IVF...\n",
      "[May 13, 02:51:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3144.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Tony Kaye birth date\" AND \"Deepa Mehta birth date\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4116, 23686,  4182,  3058,  1000,  1998,  1000,\n",
      "         2784,  2050,  2033, 22893,  4182,  3058,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:53] #> Loading codec...\n",
      "[May 13, 02:51:53] #> Loading IVF...\n",
      "[May 13, 02:51:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3429.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Tony Kaye birthdate, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  4116, 23686,  4182, 13701,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 22  (0.0):  44%|████▍     | 22/50 [02:28<03:10,  6.80s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:51:57] #> Loading codec...\n",
      "[May 13, 02:51:57] #> Loading IVF...\n",
      "[May 13, 02:51:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4076.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:51:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Macy's Boise Town Square store replacement history\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 20914,  1005,  1055, 23193,  2237,  2675,  3573,\n",
      "         6110,  2381,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:00] #> Loading codec...\n",
      "[May 13, 02:52:00] #> Loading IVF...\n",
      "[May 13, 02:52:00] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Macy's Boise Town Square store replacement\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 20914,  1005,  1055, 23193,  2237,  2675,  3573,\n",
      "         6110,  1000,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 23  (0.0):  46%|████▌     | 23/50 [02:35<03:06,  6.92s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:04] #> Loading codec...\n",
      "[May 13, 02:52:04] #> Loading IVF...\n",
      "[May 13, 02:52:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1400.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Lizzette Reynolds November 2007 fired\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9056, 4371, 4674, 9579, 2281, 2289, 5045, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:06] #> Loading codec...\n",
      "[May 13, 02:52:06] #> Loading IVF...\n",
      "[May 13, 02:52:06] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3844.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:06] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Manager fired in November 2007 site:Wikipedia.org, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3208,  5045,  1999,  2281,  2289,  2609,  1024, 16948,\n",
      "         1012,  8917,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 24  (0.0):  48%|████▊     | 24/50 [02:41<02:53,  6.68s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:10] #> Loading codec...\n",
      "[May 13, 02:52:10] #> Loading IVF...\n",
      "[May 13, 02:52:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4573.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Boy Lightning Calculator\" nickname P.T. Barnum, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2879,  7407, 10250, 19879,  4263,  1000,  8367,\n",
      "         1052,  1012,  1056,  1012,  8659,  2819,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:13] #> Loading codec...\n",
      "[May 13, 02:52:13] #> Loading IVF...\n",
      "[May 13, 02:52:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4928.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Boy Lightning Calculator\" P.T. Barnum, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2879,  7407, 10250, 19879,  4263,  1000,  1052,\n",
      "         1012,  1056,  1012,  8659,  2819,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 25  (0.0):  50%|█████     | 25/50 [02:48<02:48,  6.75s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:17] #> Loading codec...\n",
      "[May 13, 02:52:17] #> Loading IVF...\n",
      "[May 13, 02:52:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1346.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Duration of Battle of the Ch'ongch'on River vs. Duration of Meuse-Argonne Offensive, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9367,  1997,  2645,  1997,  1996, 10381,  1005,  2006,\n",
      "        18195,  2232,  1005,  2006,  2314,  5443,  1012,  9367,  1997,  2033,\n",
      "         8557,  1011, 12098,  7446,  2638,  5805,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:20] #> Loading codec...\n",
      "[May 13, 02:52:20] #> Loading IVF...\n",
      "[May 13, 02:52:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1368.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Duration of the Meuse-Argonne Offensive vs. Battle of the Ch'ongch'on River, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  9367,  1997,  1996,  2033,  8557,  1011, 12098,  7446,\n",
      "         2638,  5805,  5443,  1012,  2645,  1997,  1996, 10381,  1005,  2006,\n",
      "        18195,  2232,  1005,  2006,  2314,   102,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 26  (0.0):  52%|█████▏    | 26/50 [02:56<02:46,  6.93s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:25] #> Loading codec...\n",
      "[May 13, 02:52:25] #> Loading IVF...\n",
      "[May 13, 02:52:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1585.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"cricketer active 1974-1993 Australian cricket team England tour 1981 performance\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9490, 3161, 3326, 1011, 2857, 2827, 4533, 2136, 2563,\n",
      "        2778, 3261, 2836, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:27] #> Loading codec...\n",
      "[May 13, 02:52:27] #> Loading IVF...\n",
      "[May 13, 02:52:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1585.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Australian cricket team tour England 1981 player performance site:cricketarchive.com, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2827, 4533, 2136, 2778, 2563, 3261, 2447, 2836, 2609, 1024,\n",
      "        4533, 2906, 5428, 3726, 1012, 4012,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 27  (0.0):  54%|█████▍    | 27/50 [03:03<02:42,  7.08s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:32] #> Loading codec...\n",
      "[May 13, 02:52:32] #> Loading IVF...\n",
      "[May 13, 02:52:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5115.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Monte Kiffin current job\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10125, 11382, 15379,  2783,  3105,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:35] #> Loading codec...\n",
      "[May 13, 02:52:35] #> Loading IVF...\n",
      "[May 13, 02:52:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1409.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Head coach of the 1982 NC State Wolfpack football team, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2132,  2873,  1997,  1996,  3196, 13316,  2110,  4702,\n",
      "        23947,  2374,  2136,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 28  (0.0):  56%|█████▌    | 28/50 [03:10<02:35,  7.07s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:39] #> Loading codec...\n",
      "[May 13, 02:52:39] #> Loading IVF...\n",
      "[May 13, 02:52:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Ewan McGregor \"Come What May\" singer, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1041,  7447, 23023,  1000,  2272,  2054,  2089,  1000,\n",
      "         3220,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:41] #> Loading codec...\n",
      "[May 13, 02:52:41] #> Loading IVF...\n",
      "[May 13, 02:52:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Ewan McGregor \"Come What May\" singer., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1041,  7447, 23023,  1000,  2272,  2054,  2089,  1000,\n",
      "         3220,  1012,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 29  (0.0):  58%|█████▊    | 29/50 [03:17<02:25,  6.91s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:45] #> Loading codec...\n",
      "[May 13, 02:52:45] #> Loading IVF...\n",
      "[May 13, 02:52:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3912.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ivan Bella space missions\" AND \"Frank De Winne space missions\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  7332, 12101,  2686,  6416,  1000,  1998,  1000,\n",
      "         3581,  2139,  2663,  2638,  2686,  6416,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:48] #> Loading codec...\n",
      "[May 13, 02:52:48] #> Loading IVF...\n",
      "[May 13, 02:52:48] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1473.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:48] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ivan Bella Frank De Winne space travel destinations\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  7332, 12101,  3581,  2139,  2663,  2638,  2686,\n",
      "         3604, 14345,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 30  (0.0):  60%|██████    | 30/50 [03:23<02:14,  6.72s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:52] #> Loading codec...\n",
      "[May 13, 02:52:52] #> Loading IVF...\n",
      "[May 13, 02:52:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3964.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Anton Chekhov disillusioned schoolmaster play\" + \"British playwright adaptation\" + \"original work intended audience\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9865, 18178, 25495,  4487, 27572, 24117,  2098,\n",
      "         2082,  8706,  2377,  1000,  1009,  1000,  2329, 11170,  6789,  1000,\n",
      "         1009,  1000,  2434,  2147,  3832,  4378,  1000,   102,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:55] #> Loading codec...\n",
      "[May 13, 02:52:55] #> Loading IVF...\n",
      "[May 13, 02:52:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 172.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Anton Chekhov disillusioned schoolmaster play\" \"British playwright\" \"specifically written for\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  9865, 18178, 25495,  4487, 27572, 24117,  2098,\n",
      "         2082,  8706,  2377,  1000,  1000,  2329, 11170,  1000,  1000,  4919,\n",
      "         2517,  2005,  1000,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 31  (0.0):  62%|██████▏   | 31/50 [03:31<02:13,  7.01s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:52:59] #> Loading codec...\n",
      "[May 13, 02:52:59] #> Loading IVF...\n",
      "[May 13, 02:52:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1253.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:52:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Mainland US definition\" + \"Roswell International Air Center location\" + \"Pago Pago International Airport location\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  8240,  2149,  6210,  1000,  1009,  1000, 20996,\n",
      "        19228,  2248,  2250,  2415,  3295,  1000,  1009,  1000,  6643,  3995,\n",
      "         6643,  3995,  2248,  3199,  3295,  1000,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:02] #> Loading codec...\n",
      "[May 13, 02:53:02] #> Loading IVF...\n",
      "[May 13, 02:53:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1357.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Are Roswell International Air Center and Pago Pago International Airport both located in the mainland US?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024, 20996, 19228,  2248,  2250,  2415,  1998,  6643,\n",
      "         3995,  6643,  3995,  2248,  3199,  2119,  2284,  1999,  1996,  8240,\n",
      "         2149,  1029,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 32  (0.0):  64%|██████▍   | 32/50 [03:38<02:07,  7.10s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:07] #> Loading codec...\n",
      "[May 13, 02:53:07] #> Loading IVF...\n",
      "[May 13, 02:53:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3927.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Untold: The Greatest Sports Stories Never Told\" host sportscaster name, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 19662,  6392,  1024,  1996,  4602,  2998,  3441,\n",
      "         2196,  2409,  1000,  3677,  2998, 25490,  2171,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:09] #> Loading codec...\n",
      "[May 13, 02:53:09] #> Loading IVF...\n",
      "[May 13, 02:53:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4495.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . List of hosts or presenters of \"Untold: The Greatest Sports Stories Never Told\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2862,  1997,  6184,  2030, 25588,  1997,  1000, 19662,\n",
      "         6392,  1024,  1996,  4602,  2998,  3441,  2196,  2409,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 33  (0.0):  66%|██████▌   | 33/50 [03:45<01:58,  6.96s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:13] #> Loading codec...\n",
      "[May 13, 02:53:13] #> Loading IVF...\n",
      "[May 13, 02:53:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3052.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Walt Disney documentary film\" OR \"Sacro GRA documentary film\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 10598,  6373,  4516,  2143,  1000,  2030,  1000,\n",
      "        17266,  3217, 24665,  2050,  4516,  2143,  1000,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:16] #> Loading codec...\n",
      "[May 13, 02:53:16] #> Loading IVF...\n",
      "[May 13, 02:53:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1239.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Genre of Walt Disney films vs. Genre of Sacro GRA documentary, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6907,  1997, 10598,  6373,  3152,  5443,  1012,  6907,\n",
      "         1997, 17266,  3217, 24665,  2050,  4516,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 34  (0.0):  68%|██████▊   | 34/50 [03:51<01:47,  6.72s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:19] #> Loading codec...\n",
      "[May 13, 02:53:19] #> Loading IVF...\n",
      "[May 13, 02:53:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1393.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"governing organization of Gaza Strip\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  8677,  3029,  1997, 14474,  6167,  1000,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:22] #> Loading codec...\n",
      "[May 13, 02:53:22] #> Loading IVF...\n",
      "[May 13, 02:53:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1795.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Palestinian Islamic organization governing territory captured by Israel in 1967 Six-Day War, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 9302, 5499, 3029, 8677, 3700, 4110, 2011, 3956, 1999, 3476,\n",
      "        2416, 1011, 2154, 2162,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 35  (0.0):  70%|███████   | 35/50 [03:57<01:39,  6.65s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:26] #> Loading codec...\n",
      "[May 13, 02:53:26] #> Loading IVF...\n",
      "[May 13, 02:53:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2962.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Taylor Swift 2015 MTV Video Music Awards pre-show song album\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4202, 9170, 2325, 8692, 2678, 2189, 2982, 3653, 1011,\n",
      "        2265, 2299, 2201, 1000,  102,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:29] #> Loading codec...\n",
      "[May 13, 02:53:29] #> Loading IVF...\n",
      "[May 13, 02:53:29] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1434.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:29] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 205.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Taylor Swift 2015 album song premiered at MTV Video Music Awards, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 4202, 9170, 2325, 2201, 2299, 5885, 2012, 8692, 2678, 2189,\n",
      "        2982,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 36  (0.0):  72%|███████▏  | 36/50 [04:04<01:34,  6.73s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:33] #> Loading codec...\n",
      "[May 13, 02:53:33] #> Loading IVF...\n",
      "[May 13, 02:53:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3669.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Apera genus classification\" OR \"Gunnera manicata genus classification\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 23957,  2527,  3562,  5579,  1000,  2030,  1000,\n",
      "        14850,  2050, 23624, 11266,  2050,  3562,  5579,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:36] #> Loading codec...\n",
      "[May 13, 02:53:36] #> Loading IVF...\n",
      "[May 13, 02:53:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3934.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"scientific classification of Apera\" OR \"scientific classification of Gunnera manicata\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  4045,  5579,  1997, 23957,  2527,  1000,  2030,\n",
      "         1000,  4045,  5579,  1997, 14850,  2050, 23624, 11266,  2050,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 37  (0.0):  74%|███████▍  | 37/50 [04:10<01:25,  6.61s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:39] #> Loading codec...\n",
      "[May 13, 02:53:39] #> Loading IVF...\n",
      "[May 13, 02:53:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 177.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"music genres of The Drums\" OR \"music genres of Pussy Galore\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2189, 11541,  1997,  1996,  3846,  1000,  2030,\n",
      "         1000,  2189, 11541,  1997, 22418, 14891,  5686,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:42] #> Loading codec...\n",
      "[May 13, 02:53:42] #> Loading IVF...\n",
      "[May 13, 02:53:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1186.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Discography and music style comparison between The Drums and Pussy Galore., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 12532, 12565,  1998,  2189,  2806,  7831,  2090,  1996,\n",
      "         3846,  1998, 22418, 14891,  5686,  1012,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 38  (0.0):  76%|███████▌  | 38/50 [04:17<01:19,  6.60s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:46] #> Loading codec...\n",
      "[May 13, 02:53:46] #> Loading IVF...\n",
      "[May 13, 02:53:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1442.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"University of Exeter post-nominal abbreviation\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2118,  1997, 12869,  2695,  1011, 15087, 22498,\n",
      "         1000,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:49] #> Loading codec...\n",
      "[May 13, 02:53:49] #> Loading IVF...\n",
      "[May 13, 02:53:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1208.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the post-nominal abbreviation for the university where the Banded Mongoose Research Project is based?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2695,  1011, 15087, 22498,  2005,\n",
      "         1996,  2118,  2073,  1996, 25264, 12256,  3995,  9232,  2470,  2622,\n",
      "         2003,  2241,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 39  (0.0):  78%|███████▊  | 39/50 [04:24<01:13,  6.67s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:53] #> Loading codec...\n",
      "[May 13, 02:53:53] #> Loading IVF...\n",
      "[May 13, 02:53:53] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1455.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:53] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Benjamin Christensen director\" OR \"Len Wiseman director\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  6425, 24189,  2472,  1000,  2030,  1000, 18798,\n",
      "         7968,  2386,  2472,  1000,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:55] #> Loading codec...\n",
      "[May 13, 02:53:55] #> Loading IVF...\n",
      "[May 13, 02:53:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1190.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Chelsea Football Club directors list\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 9295, 2374, 2252, 5501, 2862, 1000,  102,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 40  (0.0):  80%|████████  | 40/50 [04:30<01:05,  6.56s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:53:59] #> Loading codec...\n",
      "[May 13, 02:53:59] #> Loading IVF...\n",
      "[May 13, 02:53:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3653.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:53:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . American animator who worked with Steven Cuitlahuac Melendez and Disney, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2137, 25132,  2040,  2499,  2007,  7112, 12731,  4183,\n",
      "        14431,  6692,  2278, 11463, 28787,  1998,  6373,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:02] #> Loading codec...\n",
      "[May 13, 02:54:02] #> Loading IVF...\n",
      "[May 13, 02:54:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 932.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Did Steven Cuitlahuac Melendez work on the film John Carter?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2106,  7112, 12731,  4183, 14431,  6692,  2278, 11463,\n",
      "        28787,  2147,  2006,  1996,  2143,  2198,  5708,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 41  (0.0):  82%|████████▏ | 41/50 [04:37<00:59,  6.56s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:05] #> Loading codec...\n",
      "[May 13, 02:54:05] #> Loading IVF...\n",
      "[May 13, 02:54:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3113.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Northern Rivers District rivers list Shark Creek site:gov.au, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2642,  5485,  2212,  5485,  2862, 11420,  3636,  2609,\n",
      "         1024, 18079,  1012,  8740,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:08] #> Loading codec...\n",
      "[May 13, 02:54:08] #> Loading IVF...\n",
      "[May 13, 02:54:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1194.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Shark Creek northern rivers district river\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 11420,  3636,  2642,  5485,  2212,  2314,  1000,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 42  (0.0):  84%|████████▍ | 42/50 [04:43<00:52,  6.55s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:12] #> Loading codec...\n",
      "[May 13, 02:54:12] #> Loading IVF...\n",
      "[May 13, 02:54:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 990.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Finding Dory\" 2016 animated film producer, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4531, 2079, 2854, 1000, 2355, 6579, 2143, 3135,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:15] #> Loading codec...\n",
      "[May 13, 02:54:15] #> Loading IVF...\n",
      "[May 13, 02:54:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3622.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Finding Dory 2016 film producer\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4531, 2079, 2854, 2355, 2143, 3135, 1000,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 43  (0.0):  86%|████████▌ | 43/50 [04:50<00:46,  6.59s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:19] #> Loading codec...\n",
      "[May 13, 02:54:19] #> Loading IVF...\n",
      "[May 13, 02:54:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4843.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Ferrari new owner 2000\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000, 13632,  2047,  3954,  2456,  1000,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:21] #> Loading codec...\n",
      "[May 13, 02:54:21] #> Loading IVF...\n",
      "[May 13, 02:54:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4337.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who purchased the Benetton Formula One team from Renault in 2000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  4156,  1996,  3841, 20082,  2078,  5675,  2028,\n",
      "         2136,  2013, 14605,  1999,  2456,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 44  (0.0):  88%|████████▊ | 44/50 [04:57<00:40,  6.76s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:26] #> Loading codec...\n",
      "[May 13, 02:54:26] #> Loading IVF...\n",
      "[May 13, 02:54:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1573.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fredrick Law Olmsted projects in Trenton, New Jersey\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  5965, 11285,  2375, 19330,  5244,  3064,  3934,\n",
      "         1999, 17148,  1010,  2047,  3933,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:28] #> Loading codec...\n",
      "[May 13, 02:54:28] #> Loading IVF...\n",
      "[May 13, 02:54:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1283.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Fredrick Law Olmsted projects in Trenton, New Jersey\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  5965, 11285,  2375, 19330,  5244,  3064,  3934,\n",
      "         1999, 17148,  1010,  2047,  3933,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 45  (0.0):  90%|█████████ | 45/50 [05:05<00:35,  7.18s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:34] #> Loading codec...\n",
      "[May 13, 02:54:34] #> Loading IVF...\n",
      "[May 13, 02:54:34] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1365.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:34] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Cast list of Young Toscanini movie, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3459,  2862,  1997,  2402,  2000, 29378,  5498,  3185,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:38] #> Loading codec...\n",
      "[May 13, 02:54:38] #> Loading IVF...\n",
      "[May 13, 02:54:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2103.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Young Toscanini\" former senator political party Gordon Warnecke, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  2402,  2000, 29378,  5498,  1000,  2280,  5205,\n",
      "         2576,  2283,  5146, 11582, 11012,  2063,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 46  (0.0):  92%|█████████▏| 46/50 [05:13<00:29,  7.38s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:42] #> Loading codec...\n",
      "[May 13, 02:54:42] #> Loading IVF...\n",
      "[May 13, 02:54:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1745.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nazi organization publisher of German propaganda magazine André Zucca worked for, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6394,  3029,  6674,  1997,  2446, 10398,  2932,  7213,\n",
      "        16950, 16665,  2499,  2005,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:45] #> Loading codec...\n",
      "[May 13, 02:54:45] #> Loading IVF...\n",
      "[May 13, 02:54:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3855.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Nazi propaganda magazine André Zucca worked for during World War II, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6394, 10398,  2932,  7213, 16950, 16665,  2499,  2005,\n",
      "         2076,  2088,  2162,  2462,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 47  (0.0):  94%|█████████▍| 47/50 [05:20<00:22,  7.37s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:49] #> Loading codec...\n",
      "[May 13, 02:54:49] #> Loading IVF...\n",
      "[May 13, 02:54:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1456.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Bill Ponsford profession\" \"Bill Woodfull profession\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1000,  3021, 13433,  3619,  3877,  9518,  1000,  1000,\n",
      "         3021,  3536,  3993,  2140,  9518,  1000,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:52] #> Loading codec...\n",
      "[May 13, 02:54:52] #> Loading IVF...\n",
      "[May 13, 02:54:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1422.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What sport did Bill Ponsford and Bill Woodfull play?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4368,  2106,  3021, 13433,  3619,  3877,  1998,\n",
      "         3021,  3536,  3993,  2140,  2377,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 48  (0.0):  96%|█████████▌| 48/50 [05:27<00:14,  7.05s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:56] #> Loading codec...\n",
      "[May 13, 02:54:56] #> Loading IVF...\n",
      "[May 13, 02:54:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1422.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Films Suzana S. Drobnjaković Ponti acted in based on books, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3152, 10514, 13471,  2050,  1055,  1012,  2852, 16429,\n",
      "         2078, 18317,  9142, 21179,  2072,  6051,  1999,  2241,  2006,  2808,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:54:58] #> Loading codec...\n",
      "[May 13, 02:54:58] #> Loading IVF...\n",
      "[May 13, 02:54:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4655.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:54:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Suzana S. Drobnjaković Ponti filmography based on books adaptations, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 10514, 13471,  2050,  1055,  1012,  2852, 16429,  2078,\n",
      "        18317,  9142, 21179,  2072,  2143,  9888,  2241,  2006,  2808, 17241,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 49  (0.0):  98%|█████████▊| 49/50 [05:34<00:07,  7.00s/it]Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:55:02] #> Loading codec...\n",
      "[May 13, 02:55:02] #> Loading IVF...\n",
      "[May 13, 02:55:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:55:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Location of Election Law Journal headquarters\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 3295, 1997, 2602, 2375, 3485, 4075, 1000,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 02:55:05] #> Loading codec...\n",
      "[May 13, 02:55:05] #> Loading IVF...\n",
      "[May 13, 02:55:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1179.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 02:55:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Election Law Journal founding city\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 2602, 2375, 3485, 4889, 2103, 1000,  102,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 50  (0.0): 100%|██████████| 50/50 [05:40<00:00,  6.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dedcc th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dedcc td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dedcc_row0_col0, #T_dedcc_row0_col1, #T_dedcc_row0_col2, #T_dedcc_row0_col3, #T_dedcc_row0_col4, #T_dedcc_row0_col5, #T_dedcc_row1_col0, #T_dedcc_row1_col1, #T_dedcc_row1_col2, #T_dedcc_row1_col3, #T_dedcc_row1_col4, #T_dedcc_row1_col5, #T_dedcc_row2_col0, #T_dedcc_row2_col1, #T_dedcc_row2_col2, #T_dedcc_row2_col3, #T_dedcc_row2_col4, #T_dedcc_row2_col5, #T_dedcc_row3_col0, #T_dedcc_row3_col1, #T_dedcc_row3_col2, #T_dedcc_row3_col3, #T_dedcc_row3_col4, #T_dedcc_row3_col5, #T_dedcc_row4_col0, #T_dedcc_row4_col1, #T_dedcc_row4_col2, #T_dedcc_row4_col3, #T_dedcc_row4_col4, #T_dedcc_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dedcc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dedcc_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_dedcc_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_dedcc_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_dedcc_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_dedcc_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_dedcc_level0_col5\" class=\"col_heading level0 col5\" >gold_passages_retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dedcc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dedcc_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_dedcc_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_dedcc_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_dedcc_row0_col3\" class=\"data row0 col3\" >[\"Shenzhen Peng City (2019–present)\\nOn 20 February 2019, it was announced that CFG as well as UBTECH and China Sports Capital had acquired Sichuan Jiuniu F.C.\\n...</td>\n",
       "      <td id=\"T_dedcc_row0_col4\" class=\"data row0 col4\" >No</td>\n",
       "      <td id=\"T_dedcc_row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dedcc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dedcc_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_dedcc_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_dedcc_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_dedcc_row1_col3\" class=\"data row1 col3\" >['and Goal of the Season. The Young Player of the Season award is given to the most outstanding U-23 player starting from the 2019–20 season.\\nThe...</td>\n",
       "      <td id=\"T_dedcc_row1_col4\" class=\"data row1 col4\" >NHL</td>\n",
       "      <td id=\"T_dedcc_row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dedcc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dedcc_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_dedcc_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_dedcc_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_dedcc_row2_col3\" class=\"data row2 col3\" >['Fourteen Liverpool fans received convictions for involuntary manslaughter.\\nFagan had announced his retirement just before the disaster and Kenny Dalglish was appointed as player-manager. During his...</td>\n",
       "      <td id=\"T_dedcc_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_dedcc_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dedcc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dedcc_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_dedcc_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_dedcc_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_dedcc_row3_col3\" class=\"data row3 col3\" >[\"A new training ground was constructed at the site for £45 million, which opened in 2012. The 77-acre site has 15 grass pitches and one-and-a-half...</td>\n",
       "      <td id=\"T_dedcc_row3_col4\" class=\"data row3 col4\" >Irwell</td>\n",
       "      <td id=\"T_dedcc_row3_col5\" class=\"data row3 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dedcc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_dedcc_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_dedcc_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_dedcc_row4_col2\" class=\"data row4 col2\" >{'Ealhswith', 'Æthelweard (son of Alfred)'}</td>\n",
       "      <td id=\"T_dedcc_row4_col3\" class=\"data row4 col3\" >[\"Promoted to the board a few days after the Munich air disaster, Louis Edwards, a friend of Matt Busby, began acquiring shares in the club;...</td>\n",
       "      <td id=\"T_dedcc_row4_col4\" class=\"data row4 col4\" >Alfred the Great</td>\n",
       "      <td id=\"T_dedcc_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f00a791d580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## Retrieval Score for RAG: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## Retrieval Score for RAG: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## Retrieval Score for uncompiled Baleen: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## Retrieval Score for uncompiled Baleen: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## Retrieval Score for compiled Baleen: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## Retrieval Score for compiled Baleen: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\n",
    "compiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)\n",
    "uncompiled_baleen_retrieval_score = evaluate_on_hotpotqa(uncompiled_baleen, metric=gold_passages_retrieved)\n",
    "compiled_baleen_retrieval_score = evaluate_on_hotpotqa(compiled_baleen, metric=gold_passages_retrieved)\n",
    "\n",
    "print(f\"## Retrieval Score for RAG: {compiled_rag_retrieval_score}\")\n",
    "print(f\"## Retrieval Score for uncompiled Baleen: {uncompiled_baleen_retrieval_score}\")\n",
    "print(f\"## Retrieval Score for compiled Baleen: {compiled_baleen_retrieval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 03:35:00] #> Loading codec...\n",
      "[May 13, 03:35:00] #> Loading IVF...\n",
      "[May 13, 03:35:00] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2759.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 03:35:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . \"Premier League manager with most titles won\", \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 1000, 4239, 2223, 3208, 2007, 2087, 4486, 2180, 1000,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ubuntu/miniconda3/envs/dspy/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index EPL for the first time... This may take a few seconds\n",
      "[May 13, 03:35:04] #> Loading codec...\n",
      "[May 13, 03:35:04] #> Loading IVF...\n",
      "[May 13, 03:35:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2219.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 13, 03:35:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Most successful manager in Premier League titles won., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2087, 3144, 3208, 1999, 4239, 2223, 4486, 2180, 1012,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Who is the most successful manager in the premier league and how many titles did he win?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Who is the most successful manager in the premier league and how many titles did he win?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicted Answer: Sir Alex Ferguson won <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> league titles.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Predicted Answer: Sir Alex Ferguson won \u001b[1;36m13\u001b[0m league titles.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Contexts <span style=\"font-weight: bold\">(</span>truncated<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Arsène Wenger is the longest-serving manager, having been in charge of Arsenal in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the Premier League from 1996 to his departure at the conclusion of the 2017–18 season, and holds the record for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">most m...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Sir Alex Ferguson is the club's longest-serving and most successful manager, winning 38 trophies, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including 13 league titles, five FA Cups, and two Champions League titles between 1986 and 2013. In th...\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden period in the 1930s. He </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helped introduce the WM formation, floodlights, and shirt numbers; he also added the wh...'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Pep Guardiola, former</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">head coach of Barcelona and Bayern Munich, was confirmed to become Manchester City's new manager on 1 February </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2016, with the announcement having been made several months before ...\"</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Contexts \u001b[1m(\u001b[0mtruncated\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Arsène Wenger is the longest-serving manager, having been in charge of Arsenal in\u001b[0m\n",
       "\u001b[32mthe Premier League from 1996 to his departure at the conclusion of the 2017–18 season, and holds the record for \u001b[0m\n",
       "\u001b[32mmost m...'\u001b[0m, \u001b[32m\"Sir Alex Ferguson is the club's longest-serving and most successful manager, winning 38 trophies, \u001b[0m\n",
       "\u001b[32mincluding 13 league titles, five FA Cups, and two Champions League titles between 1986 and 2013. In th...\"\u001b[0m, \n",
       "\u001b[32m'Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden period in the 1930s. He \u001b[0m\n",
       "\u001b[32mhelped introduce the WM formation, floodlights, and shirt numbers; he also added the wh...'\u001b[0m, \u001b[32m\"Pep Guardiola, former\u001b[0m\n",
       "\u001b[32mhead coach of Barcelona and Bayern Munich, was confirmed to become Manchester City's new manager on 1 February \u001b[0m\n",
       "\u001b[32m2016, with the announcement having been made several months before ...\"\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Who is the most successful manager in the premier league and how many titles did he win?\"\n",
    "pred = compiled_baleen(query)\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Answer: Big Machine Records\n",
      "\n",
      "Question: On the coast of what ocean is the birthplace of Diogal Sakho?\n",
      "Answer: Atlantic\n",
      "\n",
      "Question: Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where?\n",
      "Answer: space\n",
      "\n",
      "Question: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?\n",
      "Answer: Buena Vista Distribution\n",
      "\n",
      "Question: Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?\n",
      "Answer: Aleem Sarwar Dar\n",
      "\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Answer: Rosario Dawson\n",
      "\n",
      "Question: This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?\n",
      "Answer: The Waltz King\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Answer: Self\n",
      "\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Answer: 1950\n",
      "\n",
      "Question: The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?\n",
      "Answer: 2010\n",
      "\n",
      "Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?\n",
      "Answer: Tae Kwon Do Times\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: which American actor was Candace Kita guest starred with\n",
      "Answer: Bill Murray\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 1 and 100 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Arsène Wenger is the longest-serving manager, having been in charge of Arsenal in the Premier League from 1996 to his departure at the conclusion of the 2017–18 season, and holds the record for most matches managed in the Premier League with 828, all with Arsenal. He broke the record set by Alex Ferguson, who had managed 810 matches with Manchester United from the Premier League's inception to his retirement at the end of the 2012–13 season. Ferguson was in charge of Manchester United from November 1986 until his retirement at the end of the 2012–13 season, meaning he was manager for the last five years of the old Football League First Division and all of the first 21 seasons of the Premier League.\n",
      "Notably, since its creation the Premier League has never been won by an English manager.»\n",
      "[2] «Sir Alex Ferguson is the club's longest-serving and most successful manager, winning 38 trophies, including 13 league titles, five FA Cups, and two Champions League titles between 1986 and 2013. In the 1998–99 season, under Ferguson, the club became the first in the history of English football to achieve the continental treble of the Premier League, FA Cup and UEFA Champions League. In winning the UEFA Europa League under José Mourinho in 2016–17, they became one of five clubs to have won the original three main UEFA club competitions (the Champions League, Europa League and Cup Winners' Cup).\n",
      "Manchester United is one of the most widely supported football clubs in the world and has rivalries with Liverpool, Manchester City, Arsenal and Leeds United.»\n",
      "[3] «Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden period in the 1930s. He helped introduce the WM formation, floodlights, and shirt numbers; he also added the white sleeves and brighter red to the club's jersey. Arsène Wenger is the club's longest-serving manager and has won the most trophies. He won a record seven FA Cups, and his title-winning team set an English record for the longest top-flight unbeaten league run at 49 games between 2003 and 2004, receiving the nickname The Invincibles.\n",
      "In 2006, the club moved to the nearby Emirates Stadium.»\n",
      "[4] «Pep Guardiola, former head coach of Barcelona and Bayern Munich, was confirmed to become Manchester City's new manager on 1 February 2016, with the announcement having been made several months before Manuel Pellegrini left his position. Guardiola's first season in Manchester would end trophyless, with the Blues placing third in the league standings, but the following season proved far more successful, as City won the Premier League title with the highest points total in history and broke numerous other club and English league records along the way.\n",
      "This would prove to be the start of a period of unprecedented success for Manchester City under Guardiola. Between the 2017–18 and 2022–23 Premier League seasons, City won five out of possible six league titles, only finishing second behind Liverpool in the 2019–20 season.»\n",
      "\n",
      "Question: Who is the most successful manager in the premier league and how many titles did he win?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know from the context that Sir Alex Ferguson is the most successful manager in the Premier League. He won 13 league titles.\n",
      "\n",
      "Answer: Sir Alex Ferguson won 13 league titles.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Contex &amp; Reasoning:\n",
       "\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> «Arsène Wenger is the longest-serving manager, having been in charge of Arsenal in the Premier League from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>\n",
       "to his departure at the conclusion of the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> season, and holds the record for most matches managed in the \n",
       "Premier League with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">828</span>, all with Arsenal. He broke the record set by Alex Ferguson, who had managed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span> matches \n",
       "with Manchester United from the Premier League's inception to his retirement at the end of the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2012</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> season. \n",
       "Ferguson was in charge of Manchester United from November <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1986</span> until his retirement at the end of the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2012</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> \n",
       "season, meaning he was manager for the last five years of the old Football League First Division and all of the \n",
       "first <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> seasons of the Premier League.\n",
       "Notably, since its creation the Premier League has never been won by an English manager.»\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> «Sir Alex Ferguson is the club's longest-serving and most successful manager, winning <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> trophies, including <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
       "league titles, five FA Cups, and two Champions League titles between <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1986</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2013</span>. In the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1998</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span> season, under \n",
       "Ferguson, the club became the first in the history of English football to achieve the continental treble of the \n",
       "Premier League, FA Cup and UEFA Champions League. In winning the UEFA Europa League under José Mourinho in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "they became one of five clubs to have won the original three main UEFA club competitions <span style=\"font-weight: bold\">(</span>the Champions League, \n",
       "Europa League and Cup Winners' Cup<span style=\"font-weight: bold\">)</span>.\n",
       "Manchester United is one of the most widely supported football clubs in the world and has rivalries with Liverpool,\n",
       "Manchester City, Arsenal and Leeds United.»\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> «Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden period in the 1930s. \n",
       "He helped introduce the WM formation, floodlights, and shirt numbers; he also added the white sleeves and brighter \n",
       "red to the club's jersey. Arsène Wenger is the club's longest-serving manager and has won the most trophies. He won\n",
       "a record seven FA Cups, and his title-winning team set an English record for the longest top-flight unbeaten league\n",
       "run at <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> games between <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2003</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2004</span>, receiving the nickname The Invincibles.\n",
       "In <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2006</span>, the club moved to the nearby Emirates Stadium.»\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> «Pep Guardiola, former head coach of Barcelona and Bayern Munich, was confirmed to become Manchester City's new\n",
       "manager on <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> February <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>, with the announcement having been made several months before Manuel Pellegrini left his\n",
       "position. Guardiola's first season in Manchester would end trophyless, with the Blues placing third in the league \n",
       "standings, but the following season proved far more successful, as City won the Premier League title with the \n",
       "highest points total in history and broke numerous other club and English league records along the way.\n",
       "This would prove to be the start of a period of unprecedented success for Manchester City under Guardiola. Between \n",
       "the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> Premier League seasons, City won five out of possible six league titles, only finishing \n",
       "second behind Liverpool in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2019</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> season.»\n",
       "\n",
       "Question: Who is the most successful manager in the premier league and how many titles did he win?\n",
       "\n",
       "Reasoning: Let's think step by step in order to\u001b<span style=\"font-weight: bold\">[</span>32m produce the answer. We know from the context that Sir Alex \n",
       "Ferguson is the most successful manager in the Premier League. He won <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> league titles.\n",
       "\n",
       "Answer: Sir Alex Ferguson won <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> league titles.\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Contex & Reasoning:\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m «Arsène Wenger is the longest-serving manager, having been in charge of Arsenal in the Premier League from \u001b[1;36m1996\u001b[0m\n",
       "to his departure at the conclusion of the \u001b[1;36m2017\u001b[0m–\u001b[1;36m18\u001b[0m season, and holds the record for most matches managed in the \n",
       "Premier League with \u001b[1;36m828\u001b[0m, all with Arsenal. He broke the record set by Alex Ferguson, who had managed \u001b[1;36m810\u001b[0m matches \n",
       "with Manchester United from the Premier League's inception to his retirement at the end of the \u001b[1;36m2012\u001b[0m–\u001b[1;36m13\u001b[0m season. \n",
       "Ferguson was in charge of Manchester United from November \u001b[1;36m1986\u001b[0m until his retirement at the end of the \u001b[1;36m2012\u001b[0m–\u001b[1;36m13\u001b[0m \n",
       "season, meaning he was manager for the last five years of the old Football League First Division and all of the \n",
       "first \u001b[1;36m21\u001b[0m seasons of the Premier League.\n",
       "Notably, since its creation the Premier League has never been won by an English manager.»\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m «Sir Alex Ferguson is the club's longest-serving and most successful manager, winning \u001b[1;36m38\u001b[0m trophies, including \u001b[1;36m13\u001b[0m\n",
       "league titles, five FA Cups, and two Champions League titles between \u001b[1;36m1986\u001b[0m and \u001b[1;36m2013\u001b[0m. In the \u001b[1;36m1998\u001b[0m–\u001b[1;36m99\u001b[0m season, under \n",
       "Ferguson, the club became the first in the history of English football to achieve the continental treble of the \n",
       "Premier League, FA Cup and UEFA Champions League. In winning the UEFA Europa League under José Mourinho in \u001b[1;36m2016\u001b[0m–\u001b[1;36m17\u001b[0m,\n",
       "they became one of five clubs to have won the original three main UEFA club competitions \u001b[1m(\u001b[0mthe Champions League, \n",
       "Europa League and Cup Winners' Cup\u001b[1m)\u001b[0m.\n",
       "Manchester United is one of the most widely supported football clubs in the world and has rivalries with Liverpool,\n",
       "Manchester City, Arsenal and Leeds United.»\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m «Herbert Chapman won the club its first silverware, and his legacy enabled a trophy-laden period in the 1930s. \n",
       "He helped introduce the WM formation, floodlights, and shirt numbers; he also added the white sleeves and brighter \n",
       "red to the club's jersey. Arsène Wenger is the club's longest-serving manager and has won the most trophies. He won\n",
       "a record seven FA Cups, and his title-winning team set an English record for the longest top-flight unbeaten league\n",
       "run at \u001b[1;36m49\u001b[0m games between \u001b[1;36m2003\u001b[0m and \u001b[1;36m2004\u001b[0m, receiving the nickname The Invincibles.\n",
       "In \u001b[1;36m2006\u001b[0m, the club moved to the nearby Emirates Stadium.»\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m «Pep Guardiola, former head coach of Barcelona and Bayern Munich, was confirmed to become Manchester City's new\n",
       "manager on \u001b[1;36m1\u001b[0m February \u001b[1;36m2016\u001b[0m, with the announcement having been made several months before Manuel Pellegrini left his\n",
       "position. Guardiola's first season in Manchester would end trophyless, with the Blues placing third in the league \n",
       "standings, but the following season proved far more successful, as City won the Premier League title with the \n",
       "highest points total in history and broke numerous other club and English league records along the way.\n",
       "This would prove to be the start of a period of unprecedented success for Manchester City under Guardiola. Between \n",
       "the \u001b[1;36m2017\u001b[0m–\u001b[1;36m18\u001b[0m and \u001b[1;36m2022\u001b[0m–\u001b[1;36m23\u001b[0m Premier League seasons, City won five out of possible six league titles, only finishing \n",
       "second behind Liverpool in the \u001b[1;36m2019\u001b[0m–\u001b[1;36m20\u001b[0m season.»\n",
       "\n",
       "Question: Who is the most successful manager in the premier league and how many titles did he win?\n",
       "\n",
       "Reasoning: Let's think step by step in order to\u001b\u001b[1m[\u001b[0m32m produce the answer. We know from the context that Sir Alex \n",
       "Ferguson is the most successful manager in the Premier League. He won \u001b[1;36m13\u001b[0m league titles.\n",
       "\n",
       "Answer: Sir Alex Ferguson won \u001b[1;36m13\u001b[0m league titles.\u001b\u001b[1m[\u001b[0m0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Contex & Reasoning:\\n\\n{history[-3358:]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
